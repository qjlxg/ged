import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# è„šæœ¬è¯´æ˜ï¼šAlpha Hunter ç»ˆæå®æˆ˜ç‰ˆ
# æ ¸å¿ƒé€»è¾‘ï¼š
# 1. [æƒ…ç»ªç›‘æµ‹] ç›‘æµ‹ä»·æ ¼æ˜¯å¦æ¶¨è¿‡å¤´ï¼ˆå¤ªçƒ«ï¼‰æˆ–è·Œé€äº†ï¼ˆå¤ªå†°ï¼‰ã€‚
# 2. [äººæ°”æ£€æµ‹] ä»·æ ¼æ¶¨ä½†æ²¡äººè·Ÿï¼ˆè™šå‡ç¹è£ï¼‰æ—¶è‡ªåŠ¨æŠ¥è­¦ã€‚
# 3. [è‡ªåŠ¨è®°è´¦] å‘ç°å¥½æœºä¼šè‡ªåŠ¨è®°å…¥â€œsignal_tracker.csvâ€ï¼Œå¸®ä½ ç®—åç»­æ¶¨è·Œã€‚
# 4. [ç¯å¢ƒåˆ¤å®š] åŒºåˆ†ç°åœ¨æ˜¯â€œé¡ºé£å±€â€ï¼ˆå¤šå¤´ï¼‰è¿˜æ˜¯â€œé€†é£å±€â€ï¼ˆç©ºå¤´ï¼‰ã€‚
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 
TRACKER_FILE = 'signal_tracker.csv' # ä½ çš„æ¨¡æ‹ŸæŒä»“å°è´¦æœ¬

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        full_df = pd.read_csv(file_path, encoding='utf-8-sig')
        if len(full_df) < 60: return None
        full_df.columns = [c.strip() for c in full_df.columns]
        
        df = full_df.tail(120).copy()
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        vol_series = df['æˆäº¤é¢']
        
        # --- [è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡] ---
        ma20_s = close_series.rolling(20).mean()
        ma60_s = close_series.rolling(60).mean()
        ma20, ma60 = ma20_s.iloc[-1], ma60_s.iloc[-1]
        
        # ä»·æ ¼ç¦»å®¶ï¼ˆå‡çº¿ï¼‰çš„è¿œè¿‘
        dist_pct = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        # æƒ…ç»ªæ¸©åº¦ (RSI)
        temp = calculate_rsi(close_series).iloc[-1]
        
        # æ´»è·ƒåº¦ (é‡èƒ½æ¯”)
        pop = vol_series.tail(5).mean() / (vol_series.tail(20).mean() + 1e-9)
        
        # æ³¢åŠ¨å¼¹æ€§ (ATR)
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        flex = (high_low.rolling(14).mean().iloc[-1] / latest['æ”¶ç›˜']) * 100

        # --- [é€»è¾‘åˆ¤å®š] ---
        # ç¯å¢ƒåˆ¤æ–­
        env = "é¡ºé£å±€(å¼º)" if ma20 > ma60 else "é€†é£å±€(å¼±)"
        
        # æ¨ªç›˜ç£¨æ´‹å·¥åˆ¤å®š
        sideways_limit = max(0.018, flex * 0.5 / 100)
        is_boring = ((close_series - ma20_s) / ma20_s).abs() < sideways_limit
        boring_days = 0
        for val in reversed(is_boring.values):
            if val: boring_days += 1
            else: break
            
        # è™šå‡ç¹è£åˆ¤å®š (æ¶¨äº†ä½†æ²¡äººæ°”)
        fake_up = (latest['æ”¶ç›˜'] > ma20) and (pop < 0.8)
        
        # åˆå§‹ç»“è®º
        desc, act, multi, star = "æ­£å¸¸æ³¢åŠ¨", "è¯¥ä¹°ä¹°è¯¥å–å–", "1.0x", "â˜…â˜…â˜…â˜†â˜†"
        is_signal = False 

        # A. æŠ„åº•é€»è¾‘ (å¤§ç™½è¯ç‰ˆ)
        if temp < 38:
            desc, star, is_signal = "ğŸ”¥è·Œé€äº†", "â˜…â˜…â˜…â˜…â˜†", True
            act = "å¯ä»¥åˆ†æ‰¹ä¹°"
            if temp < 32:
                desc, act, multi = "ğŸš¨æåº¦å†°ç‚¹", "åªä¹°ä¸å–/å¤§èƒ†åŠ ä»“", "1.5x"
                if pop > 1.15 and dist_pct < -4.5:
                    desc, star, act, multi = "ğŸ’é»„é‡‘å‘", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›æ¡é’±", "2.0x"
        
        # B. é£é™©é€»è¾‘
        elif temp > 70 or fake_up:
            star = "â˜…â˜…â˜†â˜†â˜†"
            if fake_up:
                desc, act = "ğŸš«è™šå‡ç¹è£", "åˆ«è¿½ï¼å°å¿ƒè¢«å¥—"
            else:
                desc, act = "âš ï¸å¤ªçƒ«äº†", "è§å¥½å°±æ”¶/åˆ†æ‰¹ç¦»åœº"
        
        # C. çªç ´é€»è¾‘
        elif env == "é¡ºé£å±€(å¼º)" and 0 < dist_pct < 2.5 and boring_days >= 4:
            desc, star, act = "ğŸš€è¦èµ·é£", "â˜…â˜…â˜…â˜…â˜†", "æ‹¿ç¨³äº†ç­‰æ¶¨"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'analysis': {
                'ä»£ç ': code, 'ç°ä»·': latest['æ”¶ç›˜'], 'æƒ…ç»ªæ¸©åº¦': round(temp, 1),
                'å½“å‰ç¯å¢ƒ': env, 'ç¦»å®¶è·ç¦»%': round(dist_pct, 2), 'äººæ°”å€¼': round(pop, 2),
                'æ³¢åŠ¨å¼¹æ€§%': round(flex, 2), 'ç£¨æ´‹å·¥å¤©æ•°': boring_days, 'å¸‚åœºè¯Šæ–­': desc,
                'ç½®ä¿¡åº¦': star, 'æ“ä½œå»ºè®®': act, 'åŠ ä»“å€æ•°': multi, 'is_signal': is_signal,
                'date': latest['æ—¥æœŸ'] if 'æ—¥æœŸ' in latest else datetime.now().strftime('%Y-%m-%d')
            },
            'history': full_df[['æ—¥æœŸ', 'æ”¶ç›˜']]
        }
    except Exception: return None

def process_backtest(new_data_list, all_hist_map):
    if os.path.exists(TRACKER_FILE):
        tracker = pd.read_csv(TRACKER_FILE)
    else:
        tracker = pd.DataFrame(columns=['ä»£ç ', 'å…¥åœºæ—¥æœŸ', 'ä¹°å…¥ä»·', '7å¤©åæ”¶ç›Š%', '14å¤©åæ”¶ç›Š%', '20å¤©åæ”¶ç›Š%', '60å¤©åæ”¶ç›Š%', 'çŠ¶æ€'])

    for item in new_data_list:
        if item['is_signal']:
            recent = tracker[(tracker['ä»£ç '] == item['ä»£ç '])].tail(1)
            if recent.empty or (datetime.now() - pd.to_datetime(recent['å…¥åœºæ—¥æœŸ'].values[0])).days > 10:
                new_row = pd.DataFrame([{
                    'ä»£ç ': item['ä»£ç '], 'å…¥åœºæ—¥æœŸ': item['date'], 'ä¹°å…¥ä»·': item['ç°ä»·'],
                    '7å¤©åæ”¶ç›Š%': np.nan, '14å¤©åæ”¶ç›Š%': np.nan, '20å¤©åæ”¶ç›Š%': np.nan, '60å¤©åæ”¶ç›Š%': np.nan, 'çŠ¶æ€': 'æŒæœ‰ä¸­'
                }])
                tracker = pd.concat([tracker, new_row], ignore_index=True)

    for idx, row in tracker.iterrows():
        code = str(row['ä»£ç ']).zfill(6)
        if code in all_hist_map:
            h_df = all_hist_map[code].copy()
            h_df['æ—¥æœŸ'] = pd.to_datetime(h_df['æ—¥æœŸ'])
            buy_dt = pd.to_datetime(row['å…¥åœºæ—¥æœŸ'])
            future = h_df[h_df['æ—¥æœŸ'] > buy_dt].copy()
            if not future.empty:
                for t in [7, 14, 20, 60]:
                    col = f'{t}å¤©åæ”¶ç›Š%'
                    if pd.isna(row[col]) and len(future) >= t:
                        p_t = future.iloc[t-1]['æ”¶ç›˜']
                        tracker.at[idx, col] = round((p_t - row['ä¹°å…¥ä»·']) / row['ä¹°å…¥ä»·'] * 100, 2)
                if len(future) >= 60: tracker.at[idx, 'çŠ¶æ€'] = 'å·²ç»“é¡¹'

    tracker.to_csv(TRACKER_FILE, index=False, encoding='utf-8-sig')
    return tracker

def main():
    target_file = None
    for f in [ETF_LIST_FILE, ETF_LIST_FILE.replace('.xlsx', '.csv')]:
        if os.path.exists(f): target_file = f; break
    if not target_file: return

    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file, engine='openpyxl')
        else: name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸš€ Alpha Hunter å¯åŠ¨ï¼šæ­£åœ¨å¸®ä½ çœ‹ç®¡ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        raw_results = p.map(analyze_fund, csv_files)
    
    analysis_results = [r['analysis'] for r in raw_results if r and r['analysis']['ä»£ç '] in name_map]
    hist_map = {r['analysis']['ä»£ç ']: r['history'] for r in raw_results if r}
    
    if not analysis_results: return
    tracker_df = process_backtest(analysis_results, hist_map)
    
    final_df = pd.DataFrame(analysis_results)
    final_df['ç®€ç§°'] = final_df['ä»£ç '].apply(lambda x: name_map[x])
    cols = ['ä»£ç ', 'ç®€ç§°', 'ç°ä»·', 'æƒ…ç»ªæ¸©åº¦', 'å½“å‰ç¯å¢ƒ', 'å¸‚åœºè¯Šæ–­', 'ç½®ä¿¡åº¦', 'æ“ä½œå»ºè®®', 'äººæ°”å€¼', 'ç£¨æ´‹å·¥å¤©æ•°']
    final_df = final_df[cols].sort_values(by=['ç½®ä¿¡åº¦', 'æƒ…ç»ªæ¸©åº¦'], ascending=[False, True])

    now = datetime.now()
    os.makedirs(now.strftime('%Y/%m'), exist_ok=True)
    save_path = os.path.join(now.strftime('%Y/%m'), f"market_scan_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')

    print(f"\nâœ… è¯Šæ–­æŠ¥å‘Šå·²ç”Ÿæˆï¼š{save_path}")
    print("-" * 90)
    print(final_df.head(10))

    print("\nğŸ“ˆ å†å²â€œä¹°å…¥â€åçš„è¡¨ç°éªŒè¯ (å¸®ä½ æµ‹è¯•è¿™å¥—æ–¹æ³•çµä¸çµ):")
    for t in [7, 14, 20, 60]:
        col = f'{t}å¤©åæ”¶ç›Š%'
        valid = tracker_df[tracker_df[col].notna()]
        if not valid.empty:
            wr = (valid[col] > 0).sum() / len(valid) * 100
            print(f" >> ä¹°å…¥{t}å¤©åï¼šæˆåŠŸç‡ {wr:.1f}%, å¹³å‡èµš {valid[col].mean():.2f}% (æ ·æœ¬:{len(valid)}ä¸ª)")
        else:
            print(f" >> ä¹°å…¥{t}å¤©åï¼šè¿˜åœ¨è§‚å¯Ÿä¸­ï¼Œè¿‡å‡ å¤©å†æ¥çœ‹...")

if __name__ == "__main__":
    main()
