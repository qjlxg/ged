import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šAlpha Hunter V3 èƒ½é‡è¶‹åŠ¿ç½‘æ ¼å…¨èƒ½ç‰ˆ (æœ€ç»ˆå®Œæ•´ç‰ˆ)
# åŒ…å«åŠŸèƒ½ï¼š
# 1. [æ ¸å¿ƒé€»è¾‘] MA20åŠ¨æ€ä¸­è½´ã€RSIé£é™©é”ã€åˆ†çº§åŠ ç ã€5æ˜Ÿé‡‘åº•åˆ¤å®š
# 2. [é‡ä»·èƒŒç¦»] æ£€æµ‹ç¼©é‡ä¸Šæ¶¨ï¼ˆè¯±å¤šï¼‰ä¸æ”¾é‡ä¸‹è·Œï¼ˆææ…Œï¼‰
# 3. [åŠ¨æ€é€‚é…] åŸºäº ATR è‡ªåŠ¨è°ƒèŠ‚ä¸åŒ ETF çš„æ¨ªç›˜åˆ¤å®šé˜ˆå€¼
# 4. [è¶‹åŠ¿è¿‡æ»¤] MA60 è¶‹åŠ¿ç”Ÿå‘½çº¿ï¼ŒåŒºåˆ†å¤šå¤´æ’åˆ—ä¸ç©ºå¤´æ’åˆ—
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        # è¯»å– 120 å¤©æ•°æ®ç¡®ä¿ MA60 å’Œ ATR è®¡ç®—å‡†ç¡®
        df = pd.read_csv(file_path, encoding='utf-8-sig').tail(120)
        if len(df) < 60: return None
        df.columns = [c.strip() for c in df.columns]
        
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        vol_series = df['æˆäº¤é¢']
        
        # --- [1. åŸºç¡€è¿‡æ»¤é€»è¾‘] ---
        turnover_raw = latest.get('æ¢æ‰‹ç‡', 0)
        try:
            turnover = float(str(turnover_raw).replace('%', ''))
        except:
            turnover = 0
        if latest['æˆäº¤é¢'] < 10000000 or turnover < 0.1: return None

        # --- [2. å…³é”®æŒ‡æ ‡è®¡ç®—] ---
        ma20_s = close_series.rolling(20).mean()
        ma60_s = close_series.rolling(60).mean()
        ma20, ma60 = ma20_s.iloc[-1], ma60_s.iloc[-1]
        
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        rsi_val = calculate_rsi(close_series).iloc[-1]
        
        # ATR åŠ¨æ€æ³¢åŠ¨ç‡é€‚é…
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        atr = high_low.rolling(14).mean().iloc[-1]
        relative_atr = (atr / latest['æ”¶ç›˜']) * 100
        
        # é‡èƒ½ç³»ç»Ÿ (5æ—¥é‡æ¯”20æ—¥é‡)
        vol_ma5 = vol_series.tail(5).mean()
        vol_ma20 = vol_series.tail(20).mean()
        vol_ratio = vol_ma5 / (vol_ma20 + 1e-9)

        # --- [3. åŠ¨æ€æ¨ªç›˜åˆ¤å®šé€»è¾‘] ---
        # è‡ªåŠ¨æ ¹æ®æ³¢åŠ¨ç‡è°ƒæ•´é˜ˆå€¼ï¼šæ³¢åŠ¨å¤§çš„å®½ï¼Œæ³¢åŠ¨å°çš„çª„
        dynamic_threshold = max(0.018, relative_atr * 0.5 / 100)
        is_sideways = ((close_series - ma20_s) / ma20_s).abs() < dynamic_threshold
        sideways_days = 0
        for val in reversed(is_sideways.values):
            if val: sideways_days += 1
            else: break

        # --- [4. çŠ¶æ€ç»¼åˆåˆ¤å®šç³»ç»Ÿ] ---
        trend_status = "å¤šå¤´æ’åˆ—" if ma20 > ma60 else "ç©ºå¤´æ’åˆ—"
        
        # æ¨ªç›˜æ€§è´¨åˆ¤å®š (åŸºäº MA20 æ–œç‡)
        sideways_type = "åŠ¨æ€æ³¢åŠ¨"
        if sideways_days >= 3:
            slope = (ma20_s.iloc[-1] - ma20_s.iloc[-5]) / 5
            if bias < 0.5 and slope <= 0: sideways_type = "ä½ä½ç­‘åº•âœ…"
            elif bias > 2.0: sideways_type = "é«˜ä½æ´¾å‘âš ï¸"
            else: sideways_type = "ä¸­ç»§æ•´ç†"

        # é‡ä»·èƒŒç¦»ä¾¦æµ‹ (ä¸Šæ¶¨ä½†æ²¡é‡ = è¯±å¤š)
        is_divergence = (latest['æ”¶ç›˜'] > ma20) and (vol_ratio < 0.8)

        # é»˜è®¤åˆå§‹çŠ¶æ€
        status, action, weight, star = "æ­£å¸¸éœ‡è¡", "å¸¸è§„ç½‘æ ¼", "1.0x", "â˜…â˜…â˜…â˜†â˜†"

        # A. æŠ„åº•åˆ¤å®š (é‡‘åº•é€»è¾‘)
        if rsi_val < 38:
            status, star, action = "ğŸ”¥æœºä¼šåŒº", "â˜…â˜…â˜…â˜…â˜†", "åˆ†æ‰¹è¡¥ä»“"
            if rsi_val < 32:
                status, action, weight = "ğŸš¨è¶…å–åŠ ç ", "æš‚åœå–å‡º/ç§¯æåŠ ç ", "1.5x"
                # é»„é‡‘å‘åˆ¤å®šï¼šä¸¥é‡è´Ÿä¹–ç¦» + ææ…Œæ”¾é‡
                if vol_ratio > 1.15 and bias < -4.5:
                    status, star, action, weight = "ğŸ’äº”æ˜Ÿé‡‘åº•", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›ä¹°å…¥/æŒæœ‰", "2.0x"
        
        # B. é£é™©ä¸èƒŒç¦»åˆ¤å®š
        elif rsi_val > 70 or is_divergence:
            star = "â˜…â˜…â˜†â˜†â˜†"
            if is_divergence:
                status, action = "ğŸš«ç¼©é‡è¯±å¤š", "åœæ­¢ä¹°å…¥/ä»…å–ä¸ä¹°"
            else:
                status, action = "âš ï¸é«˜ä½è¶…ä¹°", "ç½‘æ ¼æ”¶ç¼©/æ­¢ç›ˆ"
        
        # C. è¶‹åŠ¿çªç ´åˆ¤å®š
        elif trend_status == "å¤šå¤´æ’åˆ—" and 0 < bias < 2.5 and sideways_days >= 4:
            status, star, action = "ğŸš€è“„åŠ¿çªç ´", "â˜…â˜…â˜…â˜…â˜†", "æŒä»“å¾…æ¶¨/ç½‘æ ¼ä¸Šç§»"

        # æŒ¯å¹…è¿‡æ»¤ï¼šè¿‡æ»¤æ‰æ­»é±¼æ ‡çš„
        avg_amp = df['æŒ¯å¹…'].tail(20).mean()
        if avg_amp < 1.0: return None 

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'è¯åˆ¸ä»£ç ': code,
            'æ”¶ç›˜ä»·': latest['æ”¶ç›˜'],
            'RSI(14)': round(rsi_val, 2),
            'è¶‹åŠ¿': trend_status,
            'ä¹–ç¦»ç‡%': round(bias, 2),
            'é‡èƒ½æ¯”': round(vol_ratio, 2),
            'æ³¢åŠ¨ç‡%': round(relative_atr, 2),
            'æ¨ªç›˜å¤©æ•°': sideways_days,
            'æ¨ªç›˜æ€§è´¨': sideways_type,
            'ç½‘æ ¼çŠ¶æ€': status,
            'èƒœç‡ç½®ä¿¡åº¦': star,
            'å»ºè®®æ“ä½œ': action,
            'åŠ ç å€æ•°': weight,
            'æˆäº¤é¢(ä¸‡)': round(latest['æˆäº¤é¢'] / 10000, 2),
            '20æ—¥å‡æŒ¯å¹…%': round(avg_amp, 2)
        }
    except Exception: return None

def main():
    # æŸ¥æ‰¾åˆ—è¡¨æ–‡ä»¶
    target_file = None
    for f in [ETF_LIST_FILE, ETF_LIST_FILE.replace('.xlsx', '.csv')]:
        if os.path.exists(f):
            target_file = f
            break
    if not target_file: return

    # åŠ è½½æ˜ å°„
    try:
        if target_file.endswith('.xlsx'):
            name_df = pd.read_excel(target_file, engine='openpyxl')
        else:
            name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    # å¹¶è¡Œå¤„ç†
    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸ” å¯åŠ¨ Alpha Hunter V3... æ·±åº¦åˆ†æ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        results = p.map(analyze_fund, csv_files)
    
    valid = [r for r in results if r and r['è¯åˆ¸ä»£ç '] in name_map]
    if not valid:
        print("ğŸ’¡ å½“å‰æ— ç¬¦åˆé«˜ç½®ä¿¡åº¦ä¿¡å·çš„å“ç§ã€‚")
        return

    final_df = pd.DataFrame(valid)
    final_df['è¯åˆ¸ç®€ç§°'] = final_df['è¯åˆ¸ä»£ç '].apply(lambda x: name_map[x])
    
    # æŒ‰ç…§ç½®ä¿¡åº¦é™åºã€RSI å‡åºæ’åˆ—
    cols = ['è¯åˆ¸ä»£ç ', 'è¯åˆ¸ç®€ç§°', 'æ”¶ç›˜ä»·', 'RSI(14)', 'è¶‹åŠ¿', 'ä¹–ç¦»ç‡%', 'é‡èƒ½æ¯”', 'æ³¢åŠ¨ç‡%', 
            'æ¨ªç›˜å¤©æ•°', 'æ¨ªç›˜æ€§è´¨', 'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ', 'åŠ ç å€æ•°', 'æˆäº¤é¢(ä¸‡)', '20æ—¥å‡æŒ¯å¹…%']
    final_df = final_df[cols].sort_values(by=['èƒœç‡ç½®ä¿¡åº¦', 'RSI(14)'], ascending=[False, True])
    
    # ä¿å­˜ç»“æœ
    now = datetime.now()
    os.makedirs(now.strftime('%Y/%m'), exist_ok=True)
    save_path = os.path.join(now.strftime('%Y/%m'), f"alpha_hunter_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… æ‰«ææˆåŠŸï¼æ•°æ®ä¿å­˜åœ¨ï¼š{save_path}")
    print("-" * 80)
    # ä¿®æ­£äº†å­—æ®µåï¼Œç¡®ä¿ä¸å†æŠ¥ KeyError
    print(final_df[['è¯åˆ¸ç®€ç§°', 'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ', 'è¶‹åŠ¿', 'é‡èƒ½æ¯”']].head(10))

if __name__ == "__main__":
    main()
