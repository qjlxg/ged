import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šRSI-BOLL-VOLUME ç»ˆæèƒœç‡å¢å¼ºç‰ˆ 
# åŒ…å«ï¼šMA20åŠ¨æ€ä¸­è½´ã€RSIé£é™©é”ã€åˆ†çº§åŠ ç ã€å®‰å…¨é˜²æŠ¤ã€æ¨ªç›˜å¤©æ•°ã€å˜ç›˜é¢„è­¦
# åªæœ‰å½“ï¼ˆæ¨ªç›˜å¤©æ•° > 3ï¼‰ä¸”ï¼ˆä¹–ç¦»ç‡ < 2%ï¼‰æ—¶ï¼Œæ‰è€ƒè™‘æ‰‹åŠ¨åœ¨ç½‘æ ¼åŸºç¡€ä¸Šå¤šä¹°å…¥ 0.5 å±‚ä»“ä½ã€‚
# ==============================================================================
DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig').tail(100)
        if len(df) < 30: return None
        df.columns = [c.strip() for c in df.columns]
        
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        
        # --- [åŸºç¡€é˜²æŠ¤é€»è¾‘] ---
        turnover_raw = latest.get('æ¢æ‰‹ç‡', 0)
        try:
            turnover = float(str(turnover_raw).replace('%', ''))
        except:
            turnover = 0
        if latest['æˆäº¤é¢'] < 10000000 or turnover < 0.1: return None

        # --- [æŒ‡æ ‡è®¡ç®—] ---
        ma20_series = close_series.rolling(20).mean()
        ma20 = ma20_series.iloc[-1]
        rsi_val = calculate_rsi(close_series).iloc[-1]
        avg_amp = df['æŒ¯å¹…'].tail(20).mean()
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        vol_ratio = latest['æˆäº¤é¢'] / (df['æˆäº¤é¢'].tail(5).mean() + 1e-9)

        # --- [æ¨ªç›˜å¤©æ•°ç»Ÿè®¡] ---
        diff_pct = (close_series - ma20_series) / ma20_series
        is_sideways = diff_pct.abs() < 0.02
        sideways_days = 0
        for val in reversed(is_sideways.values):
            if val: sideways_days += 1
            else: break

        # --- [æ–°å¢ï¼šæ¨ªç›˜é™·é˜±åˆ¤å®šé€»è¾‘] ---
        sideways_type = "åŠ¨æ€æ³¢åŠ¨"
        if sideways_days >= 3:
            # å‡çº¿æœ€è¿‘5å¤©çš„æ–¹å‘ (æ–œç‡)
            slope = (ma20_series.iloc[-1] - ma20_series.iloc[-5]) / 5
            if bias < 0.5 and slope <= 0:
                sideways_type = "ä½ä½ç­‘åº•âœ…"
            elif bias > 2.0:
                sideways_type = "é«˜ä½æ´¾å‘âš ï¸"
            else:
                sideways_type = "ä¸­ç»§æ•´ç†"

        # --- [é£é™©é”ä¸èƒœç‡åˆ¤å®š] ---
        if rsi_val > 70 or avg_amp < 1.2: return None

        status, action, weight, star = "æ­£å¸¸éœ‡è¡", "å¸¸è§„ç½‘æ ¼", "1.0x", "â˜…â˜…â˜…â˜†â˜†"
        boll_pos = "ä¸­è½¨ä¸Šæ–¹(çœ‹å¼º)" if latest['æ”¶ç›˜'] > ma20 else "ä¸­è½¨ä¸‹æ–¹(çœ‹å¼±)"
        
        # é™çº§é€»è¾‘ï¼šå¦‚æœæ˜¯é«˜ä½æ´¾å‘é£é™©ï¼Œå³ä¾¿å…¶ä»–æ¡ä»¶å¥½ï¼Œä¹Ÿå°†èƒœç‡é™çº§
        if sideways_type == "é«˜ä½æ´¾å‘âš ï¸":
            star = "â˜…â˜…â˜†â˜†â˜†"
            action = "è­¦æƒ•å›æ’¤/å‡é‡ç½‘æ ¼"

        if rsi_val < 35:
            status, star = "ğŸ”¥æœºä¼šåŒº", "â˜…â˜…â˜…â˜…â˜†"
            if rsi_val < 30:
                status, action, weight, star = "ğŸš¨è¶…å–åŠ ç åŒº", "æš‚åœå–å‡º/åªä¹°ä¸å–", "1.5x - 2.0x", "â˜…â˜…â˜…â˜…â˜†"
                if vol_ratio > 1.1 and bias < -3:
                    status, star, action = "ğŸ’äº”æ˜Ÿé‡‘åº•", "â˜…â˜…â˜…â˜…â˜…", "å¼ºåŠ›åŠ ç /åªä¹°ä¸å–"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'è¯åˆ¸ä»£ç ': code,
            'æ”¶ç›˜ä»·': latest['æ”¶ç›˜'],
            'RSI(14)': round(rsi_val, 2),
            'ä¹–ç¦»ç‡%': round(bias, 2),
            'æ¨ªç›˜å¤©æ•°': sideways_days,
            'æ¨ªç›˜æ€§è´¨': sideways_type,
            'ç½‘æ ¼çŠ¶æ€': status,
            'èƒœç‡ç½®ä¿¡åº¦': star,
            'å»ºè®®æ“ä½œ': action,
            'åŠ ç å€æ•°': weight,
            'æˆäº¤é¢(ä¸‡)': round(latest['æˆäº¤é¢'] / 10000, 2),
            '20æ—¥å‡æŒ¯å¹…%': round(avg_amp, 2)
        }
    except Exception: return None

def main():
    # ... (ä¿æŒåŸæœ‰çš„åŠ è½½ç™½åå•å’Œå¹¶è¡Œå¤„ç†é€»è¾‘ä¸å˜)
    if not os.path.exists(ETF_LIST_FILE):
        alt_csv = ETF_LIST_FILE.replace('.xlsx', '.csv')
        target_file = alt_csv if os.path.exists(alt_csv) else None
        if not target_file: return
    else: target_file = ETF_LIST_FILE
    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file, engine='openpyxl')
        else:
            for enc in ['utf-8-sig', 'gbk', 'utf-8']:
                try:
                    name_df = pd.read_csv(target_file, encoding=enc)
                    break
                except: continue
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    with Pool(cpu_count()) as p:
        results = p.map(analyze_fund, csv_files)
    
    valid = [r for r in results if r and r['è¯åˆ¸ä»£ç '] in name_map]
    if not valid: return

    final_df = pd.DataFrame(valid)
    final_df['è¯åˆ¸ç®€ç§°'] = final_df['è¯åˆ¸ä»£ç '].apply(lambda x: name_map[x])
    
    # æŒ‰ç…§ç½®ä¿¡åº¦ã€æ¨ªç›˜å¤©æ•°ã€RSI æ’åº
    cols = ['è¯åˆ¸ä»£ç ', 'è¯åˆ¸ç®€ç§°', 'æ”¶ç›˜ä»·', 'RSI(14)', 'ä¹–ç¦»ç‡%', 'æ¨ªç›˜å¤©æ•°', 'æ¨ªç›˜æ€§è´¨',
            'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ', 'åŠ ç å€æ•°', 'æˆäº¤é¢(ä¸‡)', '20æ—¥å‡æŒ¯å¹…%']
    final_df = final_df[cols].sort_values(['èƒœç‡ç½®ä¿¡åº¦', 'æ¨ªç›˜å¤©æ•°'], ascending=[False, False])
    
    now = datetime.now()
    dir_path = now.strftime('%Y/%m')
    os.makedirs(dir_path, exist_ok=True)
    save_path = os.path.join(dir_path, f"best_buy_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    print(f"âœ… æ‰«æå®Œæˆï¼š{save_path}")

if __name__ == "__main__":
    main()
