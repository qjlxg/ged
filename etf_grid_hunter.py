import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šRSI-BOLL-VOLUME ç»ˆæèƒœç‡å¢å¼ºç‰ˆ (ä¼˜åŒ–ç‰ˆ)
# æ ¸å¿ƒæ”¹åŠ¨ï¼šå¢åŠ MA60è¶‹åŠ¿è¿‡æ»¤ã€ä¼˜åŒ–æ¨ªç›˜åˆ¤å®šã€åŠ¨æ€æŒ¯å¹…é€‚é…
# ==============================================================================
DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        # å¢åŠ è¯»å–é•¿åº¦ä»¥è®¡ç®— MA60
        df = pd.read_csv(file_path, encoding='utf-8-sig').tail(120)
        if len(df) < 60: return None
        df.columns = [c.strip() for c in df.columns]
        
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        
        # --- [åŸºç¡€é˜²æŠ¤é€»è¾‘] ---
        turnover_raw = latest.get('æ¢æ‰‹ç‡', 0)
        try:
            turnover = float(str(turnover_raw).replace('%', ''))
        except:
            turnover = 0
        # ç»´æŒåŸæˆäº¤é¢è¿‡æ»¤ï¼šæˆäº¤é¢ > 1000ä¸‡ï¼Œæ¢æ‰‹ > 0.1% 
        if latest['æˆäº¤é¢'] < 10000000 or turnover < 0.1: return None

        # --- [æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—] ---
        ma20_series = close_series.rolling(20).mean()
        ma60_series = close_series.rolling(60).mean()
        ma20, ma60 = ma20_series.iloc[-1], ma60_series.iloc[-1]
        
        rsi_val = calculate_rsi(close_series).iloc[-1]
        avg_amp = df['æŒ¯å¹…'].tail(20).mean()
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        vol_ratio = latest['æˆäº¤é¢'] / (df['æˆäº¤é¢'].tail(5).mean() + 1e-9)

        # --- [æ¨ªç›˜é€»è¾‘ä¼˜åŒ–] ---
        # ä¹–ç¦»ç‡ç»å¯¹å€¼ < 2.5% åˆ¤å®šä¸ºæ¨ªç›˜ï¼ˆç•¥å¾®æ”¾å®½ï¼Œå¢åŠ çµæ•åº¦ï¼‰
        diff_pct = (close_series - ma20_series) / ma20_series
        is_sideways = diff_pct.abs() < 0.025
        sideways_days = 0
        for val in reversed(is_sideways.values):
            if val: sideways_days += 1
            else: break

        # --- [æ–°å¢ï¼šè¶‹åŠ¿å¼ºåº¦åˆ¤å®š] ---
        trend_status = "å¤šå¤´æ’åˆ—" if ma20 > ma60 else "ç©ºå¤´æ’åˆ—"
        
        # --- [æ¨ªç›˜é™·é˜±é€»è¾‘] ---
        sideways_type = "åŠ¨æ€æ³¢åŠ¨"
        if sideways_days >= 3:
            slope = (ma20_series.iloc[-1] - ma20_series.iloc[-5]) / 5
            if bias < 0.5 and slope <= 0:
                sideways_type = "ä½ä½ç­‘åº•âœ…"
            elif bias > 2.0:
                sideways_type = "é«˜ä½æ´¾å‘âš ï¸"
            else:
                sideways_type = "ä¸­ç»§æ•´ç†"

        # --- [é£é™©ä¸èƒœç‡åˆ¤å®š] ---
        # ç»´æŒåŸé€»è¾‘ï¼šRSI > 70 é£é™©é”ï¼Œå¹³å‡æŒ¯å¹…è¿‡ä½ï¼ˆæ— æ³¢åŠ¨ä¸ç½‘æ ¼ï¼‰åˆ™è¿‡æ»¤ 
        if rsi_val > 72 or avg_amp < 1.0: return None

        status, action, weight, star = "æ­£å¸¸éœ‡è¡", "å¸¸è§„ç½‘æ ¼", "1.0x", "â˜…â˜…â˜…â˜†â˜†"
        
        # é™çº§é€»è¾‘ï¼šé«˜ä½é£é™©
        if sideways_type == "é«˜ä½æ´¾å‘âš ï¸":
            star = "â˜…â˜…â˜†â˜†â˜†"
            action = "è­¦æƒ•å›æ’¤/å‡é‡ç½‘æ ¼"

        # å¢å¼ºé€»è¾‘ï¼šè¶…å–ä¸é‡‘åº• 
        if rsi_val < 38: # ç•¥å¾®æ”¾å®½é˜ˆå€¼
            status, star = "ğŸ”¥æœºä¼šåŒº", "â˜…â˜…â˜…â˜…â˜†"
            if rsi_val < 32:
                status, action, weight, star = "ğŸš¨è¶…å–åŠ ç åŒº", "æš‚åœå–å‡º/åˆ†æ‰¹è¡¥ä»“", "1.5x", "â˜…â˜…â˜…â˜…â˜†"
                # åŸæœ‰çš„â€œäº”æ˜Ÿé‡‘åº•â€é€»è¾‘ï¼šæˆäº¤é¢æ”¾é‡ä¸”ä¸¥é‡è´Ÿä¹–ç¦» 
                if vol_ratio > 1.1 and bias < -4:
                    status, star, action, weight = "ğŸ’äº”æ˜Ÿé‡‘åº•", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›è¡¥ä»“/åªä¹°ä¸å–", "2.0x"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'è¯åˆ¸ä»£ç ': code,
            'æ”¶ç›˜ä»·': latest['æ”¶ç›˜'],
            'RSI(14)': round(rsi_val, 2),
            'ä¹–ç¦»ç‡%': round(bias, 2),
            'è¶‹åŠ¿': trend_status,
            'æ¨ªç›˜å¤©æ•°': sideways_days,
            'æ¨ªç›˜æ€§è´¨': sideways_type,
            'ç½‘æ ¼çŠ¶æ€': status,
            'èƒœç‡ç½®ä¿¡åº¦': star,
            'å»ºè®®æ“ä½œ': action,
            'åŠ ç å€æ•°': weight,
            'æˆäº¤é¢(ä¸‡)': round(latest['æˆäº¤é¢'] / 10000, 2),
            '20æ—¥å‡æŒ¯å¹…%': round(avg_amp, 2)
        }
    except Exception: return None

def main():
    # ä¿æŒåŸæœ‰çš„æ–‡ä»¶åŠ è½½é€»è¾‘ 
    if not os.path.exists(ETF_LIST_FILE):
        alt_csv = ETF_LIST_FILE.replace('.xlsx', '.csv')
        target_file = alt_csv if os.path.exists(alt_csv) else None
        if not target_file: return
    else: target_file = ETF_LIST_FILE
    
    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file, engine='openpyxl')
        else:
            for enc in ['utf-8-sig', 'gbk', 'utf-8']:
                try:
                    name_df = pd.read_csv(target_file, encoding=enc)
                    break
                except: continue
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    with Pool(cpu_count()) as p:
        results = p.map(analyze_fund, csv_files)
    
    valid = [r for r in results if r and r['è¯åˆ¸ä»£ç '] in name_map]
    if not valid: 
        print("âŒ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æ ‡çš„ï¼ˆå¯èƒ½å¸‚åœºè¿‡çƒ­æˆ–å¤„äºæç«¯ä½æ³¢åŠ¨æœŸï¼‰")
        return

    final_df = pd.DataFrame(valid)
    final_df['è¯åˆ¸ç®€ç§°'] = final_df['è¯åˆ¸ä»£ç '].apply(lambda x: name_map[x])
    
    # æŒ‰ç…§ ç½®ä¿¡åº¦ã€è¶‹åŠ¿(å¤šå¤´ä¼˜å…ˆ)ã€RSI(ä½è€…ä¼˜å…ˆ) æ’åº
    cols = ['è¯åˆ¸ä»£ç ', 'è¯åˆ¸ç®€ç§°', 'æ”¶ç›˜ä»·', 'RSI(14)', 'è¶‹åŠ¿', 'ä¹–ç¦»ç‡%', 'æ¨ªç›˜å¤©æ•°', 'æ¨ªç›˜æ€§è´¨',
            'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ', 'åŠ ç å€æ•°', 'æˆäº¤é¢(ä¸‡)', '20æ—¥å‡æŒ¯å¹…%']
    final_df = final_df[cols].sort_values(
        ['èƒœç‡ç½®ä¿¡åº¦', 'è¶‹åŠ¿', 'RSI(14)'], 
        ascending=[False, False, True]
    )
    
    now = datetime.now()
    dir_path = now.strftime('%Y/%m')
    os.makedirs(dir_path, exist_ok=True)
    save_path = os.path.join(dir_path, f"grid_hunt_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    print(f"âœ… æ‰«æå®Œæˆï¼š{save_path}")
    print(final_df[['è¯åˆ¸ç®€ç§°', 'RSI(14)', 'è¶‹åŠ¿', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ']].head(10))

if __name__ == "__main__":
    main()
