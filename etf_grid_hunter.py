import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šAlpha Hunter V8 ç”Ÿäº§ç¯å¢ƒå¢å¼ºç‰ˆ
# 1. [é€»è¾‘æ ¸å¿ƒ]ï¼šRSI(æƒ…ç»ª)ã€BIAS(ä¹–ç¦»)ã€VOLUME(é‡ä»·)ã€ATR(æ³¢åŠ¨)
# 2. [ç»“æœæ’åº]ï¼šä¹°å…¥æ¸…å•ç½®é¡¶ï¼Œä¸”æŒ‰ RSI ç”±ä½åˆ°é«˜(ç”±å†·åˆ°çƒ­)æ’åº
# 3. [è‡ªåŠ¨åŒ–å­˜å‚¨]ï¼šæ¯æ—¥å†³ç­–è‡ªåŠ¨å­˜å…¥ "results/å¹´/æœˆ/market_scan_æ—¥æœŸ.csv" 
# 4. [æŒä¹…åŒ–è´¦æœ¬]ï¼šsignal_tracker.csv ä¿æŒåœ¨æ ¹ç›®å½•ï¼Œç”¨äºæŒç»­å›æµ‹èƒœç‡
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 
TRACKER_FILE = 'signal_tracker.csv'    # æŒç»­å›æµ‹è´¦æœ¬
BASE_RESULT_DIR = 'results'            # ç»“æœå­˜å‚¨æ ¹ç›®å½•

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        full_df = pd.read_csv(file_path, encoding='utf-8-sig')
        if len(full_df) < 60: return None
        full_df.columns = [c.strip() for c in full_df.columns]
        df = full_df.tail(120).copy()
        latest = df.iloc[-1]
        
        # --- ç¡¬æ ¸æŒ‡æ ‡è®¡ç®— ---
        rsi_val = calculate_rsi(df['æ”¶ç›˜']).iloc[-1]
        ma20 = df['æ”¶ç›˜'].rolling(20).mean().iloc[-1]
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        vol_ratio = df['æˆäº¤é¢'].tail(5).mean() / (df['æˆäº¤é¢'].tail(20).mean() + 1e-9)
        
        # --- å†³ç­–é€»è¾‘ ---
        signal_type, reason, is_buy = "è§‚æœ›", "éœ‡è¡åŒºé—´", False

        # ä¹°å…¥è§¦å‘ (RSI < 38)
        if rsi_val < 68:
            signal_type, reason, is_buy = "å»ºè®®ä¹°å…¥", "æƒ…ç»ªå†°ç‚¹", True
            if rsi_val < 32: reason = "ä¸¥é‡è¶…è·Œ/é»„é‡‘å‘"
        # å–å‡ºè§¦å‘ (RSI > 70 æˆ– é‡ä»·èƒŒç¦»)
        elif rsi_val > 70:
            signal_type, reason = "å»ºè®®å–å‡º", "æƒ…ç»ªè¿‡çƒ­"
        elif latest['æ”¶ç›˜'] > ma20 and vol_ratio < 0.8:
            signal_type, reason = "å»ºè®®å–å‡º", "é‡ä»·èƒŒç¦»"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'analysis': {
                'æ—¥æœŸ': latest['æ—¥æœŸ'] if 'æ—¥æœŸ' in latest else datetime.now().strftime('%Y-%m-%d'),
                'ä»£ç ': code, 'ä»·æ ¼': latest['æ”¶ç›˜'], 'RSI': round(rsi_val, 1), 
                'ä¿¡å·': signal_type, 'ç†ç”±': reason, 'is_signal': is_buy,
                'åç¦»åº¦%': round(bias, 2), 'äººæ°”å€¼': round(vol_ratio, 2)
            },
            'history': full_df[['æ—¥æœŸ', 'æ”¶ç›˜']]
        }
    except: return None

def update_tracker(new_results, hist_map):
    """ç»´æŠ¤å›æµ‹è´¦æœ¬ï¼Œè®¡ç®—çœŸå®èƒœç‡"""
    cols = ['ä»£ç ', 'å…¥åœºæ—¥æœŸ', 'ä¹°å…¥ä»·', 'T+7æ”¶ç›Š%', 'T+14æ”¶ç›Š%', 'T+20æ”¶ç›Š%', 'T+60æ”¶ç›Š%', 'çŠ¶æ€']
    tracker = pd.read_csv(TRACKER_FILE) if os.path.exists(TRACKER_FILE) else pd.DataFrame(columns=cols)
    
    for item in new_results:
        if item['is_signal']:
            recent = tracker[tracker['ä»£ç '] == item['ä»£ç ']].tail(1)
            if recent.empty or (datetime.now() - pd.to_datetime(recent['å…¥åœºæ—¥æœŸ'].values[0])).days > 10:
                new_row = pd.DataFrame([[item['ä»£ç '], item['æ—¥æœŸ'], item['ä»·æ ¼'], np.nan, np.nan, np.nan, np.nan, 'æŒæœ‰ä¸­']], columns=cols)
                tracker = pd.concat([tracker, new_row], ignore_index=True)

    for idx, row in tracker.iterrows():
        code = str(row['ä»£ç ']).zfill(6)
        if code in hist_map:
            h_df = hist_map[code].copy()
            h_df['æ—¥æœŸ'] = pd.to_datetime(h_df['æ—¥æœŸ'])
            buy_dt = pd.to_datetime(row['å…¥åœºæ—¥æœŸ'])
            future = h_df[h_df['æ—¥æœŸ'] > buy_dt]
            if not future.empty:
                for t in [7, 14, 20, 60]:
                    col = f'T+{t}æ”¶ç›Š%'
                    if pd.isna(row[col]) and len(future) >= t:
                        p_t = future.iloc[t-1]['æ”¶ç›˜']
                        tracker.at[idx, col] = round((p_t - row['ä¹°å…¥ä»·']) / row['ä¹°å…¥ä»·'] * 100, 2)
                if len(future) >= 60: tracker.at[idx, 'çŠ¶æ€'] = 'å·²ç»“é¡¹'
    
    tracker.to_csv(TRACKER_FILE, index=False, encoding='utf-8-sig')
    return tracker

def main():
    # 1. åŠ è½½åç§°æ˜ å°„
    target_file = ETF_LIST_FILE if os.path.exists(ETF_LIST_FILE) else ETF_LIST_FILE.replace('.xlsx', '.csv')
    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file)
        else: name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6), name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    # 2. å¹¶è¡Œæ‰«æ
    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸš€ Alpha Hunter V8 å¯åŠ¨ï¼šæ­£åœ¨æ‰«æ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        raw_output = p.map(analyze_fund, csv_files)
    
    results = [r['analysis'] for r in raw_output if r and r['analysis']['ä»£ç '] in name_map]
    hist_map = {r['analysis']['ä»£ç ']: r['history'] for r in raw_output if r}

    # 3. æ›´æ–°å›æµ‹è´¦æœ¬
    tracker_df = update_tracker(results, hist_map)

    # 4. æ’åºé€»è¾‘ï¼šå»ºè®®ä¹°å…¥åœ¨å‰ï¼ŒæŒ‰ RSI ä»å°åˆ°å¤§æ’
    buy_list = sorted([r for r in results if r['ä¿¡å·'] == "å»ºè®®ä¹°å…¥"], key=lambda x: x['RSI'])
    sell_list = sorted([r for r in results if r['ä¿¡å·'] == "å»ºè®®å–å‡º"], key=lambda x: x['RSI'], reverse=True)

    # 5. ç”Ÿæˆå¹´æœˆç›®å½•å¹¶æ¨é€æ–‡ä»¶
    now = datetime.now()
    dir_path = os.path.join(BASE_RESULT_DIR, now.strftime('%Y'), now.strftime('%m'))
    os.makedirs(dir_path, exist_ok=True)
    file_name = f"scan_{now.strftime('%Y%m%d')}.csv"
    full_path = os.path.join(dir_path, file_name)

    all_actions = buy_list + sell_list
    if all_actions:
        output_df = pd.DataFrame(all_actions)
        output_df['ç®€ç§°'] = output_df['ä»£ç '].apply(lambda x: name_map.get(x, 'æœªçŸ¥'))
        # è°ƒæ•´ç¾åŒ–åˆ—åº
        cols = ['æ—¥æœŸ', 'ä»£ç ', 'ç®€ç§°', 'ä»·æ ¼', 'ä¿¡å·', 'ç†ç”±', 'RSI', 'åç¦»åº¦%', 'äººæ°”å€¼']
        output_df[cols].to_csv(full_path, index=False, encoding='utf-8-sig')
        print(f"âœ… å†³ç­–æŠ¥å‘Šå·²å­˜è‡³: {full_path}")

    # 6. æ§åˆ¶å°å‹å¥½è¾“å‡º
    print(f"\nğŸ“… åˆ†ææ—¥æœŸ: {now.strftime('%Y-%m-%d')}")
    print("=" * 85)
    print(f"{'ä»£ç ':<8} | {'ç®€ç§°':<12} | {'ä¿¡å·':<8} | {'RSI':<5} | {'ç†ç”±':<15}")
    print("-" * 85)
    
    for r in buy_list:
        print(f"ğŸŸ¢ {r['ä»£ç ']:<6} | {name_map[r['ä»£ç ']]:<10} | {r['ä¿¡å·']:<6} | {r['RSI']:<5} | {r['ç†ç”±']}")
    for r in sell_list:
        print(f"ğŸ”´ {r['ä»£ç ']:<6} | {name_map[r['ä»£ç ']]:<10} | {r['ä¿¡å·']:<6} | {r['RSI']:<5} | {r['ç†ç”±']}")
    
    if not all_actions:
        print("   (å½“å‰å¸‚åœºæƒ…ç»ªç¨³å®šï¼Œæ— æç«¯ä¹°å–å»ºè®®ï¼Œå»ºè®®ç½‘æ ¼æ­£å¸¸è¿è¡Œ)")
    print("=" * 85)

    # 7. æ‰“å°å†å²èƒœç‡
    print("\nğŸ“Š å†å²ä¿¡å·å¯é æ€§éªŒè¯ (signal_tracker.csv):")
    for t in [7, 14, 20, 60]:
        col = f'T+{t}æ”¶ç›Š%'
        if col in tracker_df.columns:
            valid = tracker_df[tracker_df[col].notna()]
            if not valid.empty:
                wr = (valid[col].astype(float) > 0).sum() / len(valid) * 100
                avg = valid[col].astype(float).mean()
                print(f" >> T+{t} èƒœç‡: {wr:.1f}% | å¹³å‡æ”¶ç›Š: {avg:.2f}% (æ ·æœ¬æ•°: {len(valid)})")

if __name__ == "__main__":
    main()
