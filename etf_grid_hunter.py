import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šAlpha Hunter V8.1 ç»ˆæå®æˆ˜å½’æ¡£ç‰ˆ
# æ ¸å¿ƒæŒ‡æ ‡ä¾æ®ï¼š
# 1. RSI (14æ—¥æƒ…ç»ªæ¸©åº¦)ï¼šåˆ¤å®šå¸‚åœºæ˜¯å¦è·Œé€(è¶…å–)æˆ–æ¶¨ç–¯(è¶…ä¹°)
# 2. BIAS (ä¹–ç¦»ç‡)ï¼šæµ‹é‡ä»·æ ¼åç¦»20æ—¥å‡çº¿çš„è·ç¦»ï¼Œåˆ©ç”¨å‡çº¿å¼•åŠ›æ•æ‰åå¼¹
# 3. VOLUME (é‡ä»·éªŒè¯)ï¼šé€šè¿‡5æ—¥å‡é‡/20æ—¥å‡é‡æ¯”å€¼ï¼Œè¯†åˆ«â€œç¼©é‡ä¸Šæ¶¨â€çš„éª—ç‚®é£é™©
# 4. ATR (çœŸå®æ³¢å¹…)ï¼šåŠ¨æ€é€‚é…å“ç§æ€§æ ¼ï¼Œè®¡ç®—æ›´ç²¾å‡†çš„æ¨ªç›˜ä¸æ³¢åŠ¨åŒºé—´
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 
TRACKER_FILE = 'signal_tracker.csv'    # å†å²ä¿¡å·å›æµ‹è´¦æœ¬ï¼ˆæ ¹ç›®å½•ï¼‰
BASE_RESULT_DIR = 'results'            # å†³ç­–æŠ¥å‘Šå­˜æ”¾æ ¹ç›®å½•

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        full_df = pd.read_csv(file_path, encoding='utf-8-sig')
        if len(full_df) < 60: return None
        full_df.columns = [c.strip() for c in full_df.columns]
        
        # è·å–åˆ†ææ‰€éœ€çš„è®¡ç®—ç‰‡æ®µ
        df = full_df.tail(120).copy()
        latest = df.iloc[-1]
        close_s = df['æ”¶ç›˜']
        vol_s = df['æˆäº¤é¢']
        
        # --- [æŠ€æœ¯æŒ‡æ ‡æ·±åº¦è®¡ç®—] ---
        # 1. æƒ…ç»ªæ¸©åº¦ (RSI)
        rsi_val = calculate_rsi(close_s).iloc[-1]
        
        # 2. å‡çº¿å¼•åŠ› (BIAS)
        ma20 = close_s.rolling(20).mean().iloc[-1]
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        
        # 3. èµ„é‡‘æ´»è·ƒåº¦ (æˆäº¤é‡æ¯”)
        vol_ratio = vol_s.tail(5).mean() / (vol_s.tail(20).mean() + 1e-9)
        
        # 4. æ³¢åŠ¨ç‡é€‚é… (ATR)
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        atr = high_low.rolling(14).mean().iloc[-1]
        volatility = (atr / latest['æ”¶ç›˜']) * 100

        # --- [å¤šç»´åº¦å†³ç­–ç³»ç»Ÿ] ---
        signal_type, reason, is_buy = "è§‚æœ›", "éœ‡è¡åŒºåŸŸ", False

        # ä¹°å…¥ä¿¡å·åˆ¤å®šï¼šå¿…é¡»åŒæ—¶æ»¡è¶³è¶…è·Œå’Œæƒ…ç»ªå†°ç‚¹
        if rsi_val < 38:
            signal_type, reason, is_buy = "å»ºè®®ä¹°å…¥", "æƒ…ç»ªå†°ç‚¹/ä½ä½å»ºä»“", True
            if rsi_val < 32:
                reason = "ä¸¥é‡è¶…è·Œ/é»„é‡‘å‘"
        
        # å–å‡ºä¿¡å·åˆ¤å®šï¼šè¶…ä¹°è¿‡çƒ­ æˆ– å‡ºç°ç¼©é‡è¯±å¤š
        elif rsi_val > 70:
            signal_type, reason = "å»ºè®®å–å‡º", "æƒ…ç»ªè¿‡çƒ­/é€¢é«˜æ­¢ç›ˆ"
        elif latest['æ”¶ç›˜'] > ma20 and vol_ratio < 0.8:
            signal_type, reason = "å»ºè®®å–å‡º", "ç¼©é‡ä¸Šæ¶¨/è¯±å¤šé£é™©"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'analysis': {
                'æ—¥æœŸ': latest['æ—¥æœŸ'] if 'æ—¥æœŸ' in latest else datetime.now().strftime('%Y-%m-%d'),
                'ä»£ç ': code, 'ä»·æ ¼': latest['æ”¶ç›˜'], 'RSI': round(rsi_val, 1), 
                'ä¿¡å·': signal_type, 'ç†ç”±': reason, 'is_signal': is_buy,
                'åç¦»åº¦%': round(bias, 2), 'äººæ°”å€¼': round(vol_ratio, 2),
                'æ³¢åŠ¨ç‡%': round(volatility, 2)
            },
            'history': full_df[['æ—¥æœŸ', 'æ”¶ç›˜']]
        }
    except: return None

def update_tracker(new_results, hist_map):
    """ç»´æŠ¤èƒœç‡è´¦æœ¬ï¼Œè¿½è¸ªä¹°å…¥ä¿¡å·åçš„è¡¨ç°"""
    cols = ['ä»£ç ', 'å…¥åœºæ—¥æœŸ', 'ä¹°å…¥ä»·', 'T+7æ”¶ç›Š%', 'T+14æ”¶ç›Š%', 'T+20æ”¶ç›Š%', 'T+60æ”¶ç›Š%', 'çŠ¶æ€']
    if os.path.exists(TRACKER_FILE):
        tracker = pd.read_csv(TRACKER_FILE)
    else:
        tracker = pd.DataFrame(columns=cols)

    # 1. è®°å½•ä»Šæ—¥æ–°äº§ç”Ÿçš„ä¹°å…¥ä¿¡å·
    for item in new_results:
        if item['is_signal']:
            recent = tracker[tracker['ä»£ç '] == item['ä»£ç ']].tail(1)
            # 10å¤©å†·å´æœŸï¼Œé˜²æ­¢ä¸‹è·Œè¿‡ç¨‹ä¸­ä¿¡å·åˆ·å±
            if recent.empty or (datetime.now() - pd.to_datetime(recent['å…¥åœºæ—¥æœŸ'].values[0])).days > 10:
                new_row = pd.DataFrame([[
                    item['ä»£ç '], item['æ—¥æœŸ'], item['ä»·æ ¼'], np.nan, np.nan, np.nan, np.nan, 'æŒæœ‰ä¸­'
                ]], columns=cols)
                tracker = pd.concat([tracker, new_row], ignore_index=True)

    # 2. è‡ªåŠ¨åˆ·æ–°å†å²ä¿¡å·çš„åç»­è¡¨ç°
    for idx, row in tracker.iterrows():
        code = str(row['ä»£ç ']).zfill(6)
        if code in hist_map:
            h_df = hist_map[code].copy()
            h_df['æ—¥æœŸ'] = pd.to_datetime(h_df['æ—¥æœŸ'])
            buy_dt = pd.to_datetime(row['å…¥åœºæ—¥æœŸ'])
            future_data = h_df[h_df['æ—¥æœŸ'] > buy_dt]
            if not future_data.empty:
                for t in [7, 14, 20, 60]:
                    col = f'T+{t}æ”¶ç›Š%'
                    if pd.isna(row[col]) and len(future_data) >= t:
                        p_t = future_data.iloc[t-1]['æ”¶ç›˜']
                        tracker.at[idx, col] = round((p_t - row['ä¹°å…¥ä»·']) / row['ä¹°å…¥ä»·'] * 100, 2)
                if len(future_data) >= 60:
                    tracker.at[idx, 'çŠ¶æ€'] = 'å·²ç»“é¡¹'
    
    tracker.to_csv(TRACKER_FILE, index=False, encoding='utf-8-sig')
    return tracker

def main():
    # --- èµ„æºåˆå§‹åŒ– ---
    target_file = ETF_LIST_FILE if os.path.exists(ETF_LIST_FILE) else ETF_LIST_FILE.replace('.xlsx', '.csv')
    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file)
        else: name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6), name_df['è¯åˆ¸ç®€ç§°']))
    except Exception as e:
        print(f"âŒ åˆ—è¡¨æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return

    # --- å¹¶è¡Œè®¡ç®—åˆ†æ ---
    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸš€ Alpha Hunter V8.1 å¯åŠ¨ï¼šæ­£åœ¨è¯Šæ–­ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        raw_output = p.map(analyze_fund, csv_files)
    
    analysis_results = [r['analysis'] for r in raw_output if r and r['analysis']['ä»£ç '] in name_map]
    hist_data_map = {r['analysis']['ä»£ç ']: r['history'] for r in raw_output if r}

    # --- å½’æ¡£å­˜å‚¨é€»è¾‘ ---
    # ç­›é€‰æœ‰å»ºè®®çš„å“ç§ï¼šä¹°å…¥åœ¨å‰ï¼ˆæŒ‰RSIä»ä½åˆ°é«˜ï¼‰ï¼Œå–å‡ºåœ¨å
    buy_list = sorted([r for r in analysis_results if r['ä¿¡å·'] == "å»ºè®®ä¹°å…¥"], key=lambda x: x['RSI'])
    sell_list = sorted([r for r in analysis_results if r['ä¿¡å·'] == "å»ºè®®å–å‡º"], key=lambda x: x['RSI'], reverse=True)
    all_decisions = buy_list + sell_list

    now = datetime.now()
    # è‡ªåŠ¨ç”Ÿæˆå¹´æœˆæ–‡ä»¶å¤¹ï¼šresults/2026/01/
    archive_dir = os.path.join(BASE_RESULT_DIR, now.strftime('%Y'), now.strftime('%m'))
    os.makedirs(archive_dir, exist_ok=True)
    archive_path = os.path.join(archive_dir, f"scan_{now.strftime('%Y%m%d')}.csv")

    if all_decisions:
        out_df = pd.DataFrame(all_decisions)
        out_df.insert(2, 'ç®€ç§°', out_df['ä»£ç '].apply(lambda x: name_map.get(x, 'æœªçŸ¥')))
        out_df.to_csv(archive_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ å®˜æ–¹å†³ç­–æŠ¥å‘Šå·²æŒä¹…åŒ–å­˜è‡³: {archive_path}")

    # --- åˆ·æ–°èƒœç‡å›æµ‹è´¦æœ¬ ---
    tracker_df = update_tracker(analysis_results, hist_data_map)

    # --- æ§åˆ¶å°å¯è§†åŒ–è¾“å‡º ---
    print(f"\nğŸ“… åˆ†ææŠ¥å‘Šæ—¥æœŸ: {now.strftime('%Y-%m-%d')}")
    print("=" * 90)
    print(f"{'ä»£ç ':<8} | {'ç®€ç§°':<12} | {'ä»·æ ¼':<7} | {'RSI':<5} | {'åç¦»åº¦%':<8} | {'å»ºè®®å†³ç­–'}")
    print("-" * 90)
    
    if not all_decisions:
        print("   (å½“å‰å¸‚åœºæƒ…ç»ªç¨³å®šï¼Œæ— æç«¯ä¹°å–å»ºè®®ï¼Œå»ºè®®ç°æœ‰ç½‘æ ¼ç­–ç•¥æ­£å¸¸è¿è¡Œ)")
    else:
        for r in buy_list:
            print(f"ğŸŸ¢ {r['ä»£ç ']:<6} | {name_map[r['ä»£ç ']]:<10} | {r['ä»·æ ¼']:<7} | {r['RSI']:<5} | {r['åç¦»åº¦%']:<8} | {r['ä¿¡å·']}({r['ç†ç”±']})")
        for r in sell_list:
            print(f"ğŸ”´ {r['ä»£ç ']:<6} | {name_map[r['ä»£ç ']]:<10} | {r['ä»·æ ¼']:<7} | {r['RSI']:<5} | {r['åç¦»åº¦%']:<8} | {r['ä¿¡å·']}({r['ç†ç”±']})")
    print("=" * 90)

    # --- èƒœç‡å®æ—¶ç®€æŠ¥ ---
    print("\nğŸ“ˆ å†å²ä¿¡å·èƒœç‡å®æ—¶ç›‘æ§ (åŸºäº signal_tracker.csv):")
    for t in [7, 14, 20, 60]:
        col = f'T+{t}æ”¶ç›Š%'
        if col in tracker_df.columns:
            valid_rows = tracker_df[tracker_df[col].notna()]
            if not valid_rows.empty:
                win_rate = (valid_rows[col].astype(float) > 0).sum() / len(valid_rows) * 100
                avg_ret = valid_rows[col].astype(float).mean()
                print(f" >> ä¹°å…¥{t:2d}å¤©å: èƒœç‡ {win_rate:5.1f}% | å¹³å‡æ”¶ç›Š {avg_ret:5.2f}% (æ ·æœ¬æ•°:{len(valid_rows)})")
            else:
                print(f" >> ä¹°å…¥{t:2d}å¤©å: æ ·æœ¬æ•°æ®ç§¯ç´¯ä¸­...")

if __name__ == "__main__":
    main()
