import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šAlpha Hunter V5 ç»ˆæå®æˆ˜éªŒè¯ç‰ˆ
# æ ¸å¿ƒåŠŸèƒ½ï¼š
# 1. [å…¨åŠŸèƒ½é€»è¾‘] ä¿ç•™V3æ‰€æœ‰é‡ä»·ã€è¶‹åŠ¿ã€åŠ¨æ€ATRã€æ¨ªç›˜åˆ¤å®šé€»è¾‘
# 2. [æ¨¡æ‹Ÿå®ç›˜] å‡ºç°ä¿¡å·å½“å¤©è‡ªåŠ¨â€œè™šæ‹Ÿä¹°å…¥â€ï¼Œè®°å½•æ”¶ç›˜ä»·
# 3. [èƒœç‡è¿½è¸ª] è‡ªåŠ¨åˆ·æ–°å¹¶è®¡ç®— T+7, T+14, T+20, T+60 çš„çœŸå®æ”¶ç›Šä¸èƒœç‡
# 4. [æŒä¹…åŒ–è´¦æœ¬] ç»“æœå­˜å…¥ signal_tracker.csvï¼Œéšæ—¥æœŸæ¨ç§»è‡ªåŠ¨æ›´æ–°å†å²è¡¨ç°
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 
TRACKER_FILE = 'signal_tracker.csv' # æ¨¡æ‹Ÿä¹°å…¥è®°å½•è´¦æœ¬

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        # ä¸ºäº†å›æµ‹å’ŒMA60ï¼Œè¯»å–è¶³å¤Ÿé•¿çš„æ•°æ®
        full_df = pd.read_csv(file_path, encoding='utf-8-sig')
        if len(full_df) < 60: return None
        full_df.columns = [c.strip() for c in full_df.columns]
        
        # æˆªå–è®¡ç®—ç”¨çš„ç‰‡æ®µ
        df = full_df.tail(120).copy()
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        vol_series = df['æˆäº¤é¢']
        
        # --- [æŒ‡æ ‡è®¡ç®—] ---
        ma20_s = close_series.rolling(20).mean()
        ma60_s = close_series.rolling(60).mean()
        ma20, ma60 = ma20_s.iloc[-1], ma60_s.iloc[-1]
        rsi_val = calculate_rsi(close_series).iloc[-1]
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        atr = high_low.rolling(14).mean().iloc[-1]
        relative_atr = (atr / latest['æ”¶ç›˜']) * 100
        vol_ratio = vol_series.tail(5).mean() / (vol_series.tail(20).mean() + 1e-9)

        # --- [é€»è¾‘åˆ¤å®š] ---
        trend_status = "å¤šå¤´æ’åˆ—" if ma20 > ma60 else "ç©ºå¤´æ’åˆ—"
        dynamic_threshold = max(0.018, relative_atr * 0.5 / 100)
        is_sideways = ((close_series - ma20_s) / ma20_s).abs() < dynamic_threshold
        sideways_days = 0
        for val in reversed(is_sideways.values):
            if val: sideways_days += 1
            else: break
            
        is_divergence = (latest['æ”¶ç›˜'] > ma20) and (vol_ratio < 0.8)
        
        status, action, weight, star = "æ­£å¸¸éœ‡è¡", "å¸¸è§„ç½‘æ ¼", "1.0x", "â˜…â˜…â˜…â˜†â˜†"
        is_buy_signal = False # æ˜¯å¦è§¦å‘è®°å½•

        if rsi_val < 38:
            status, star, is_buy_signal = "ğŸ”¥æœºä¼šåŒº", "â˜…â˜…â˜…â˜…â˜†", True
            if rsi_val < 32:
                status, action, weight = "ğŸš¨è¶…å–åŠ ç ", "æš‚åœå–å‡º/ç§¯æä¹°å…¥", "1.5x"
                if vol_ratio > 1.15 and bias < -4.5:
                    status, star, action, weight = "ğŸ’äº”æ˜Ÿé‡‘åº•", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›ä¹°å…¥/æŒæœ‰", "2.0x"
        elif is_divergence:
            status, action, star = "ğŸš«ç¼©é‡è¯±å¤š", "åœæ­¢ä¹°å…¥/ä»…å–å‡º", "â˜…â˜…â˜†â˜†â˜†"

        code = os.path.basename(file_path).replace('.csv', '')
        
        # è¿”å›åˆ†ææ•°æ®ç”¨äºå½“æ—¥å±•ç¤ºï¼Œè¿”å›å…¨é‡å†å²ç”¨äºå›æµ‹æ›´æ–°
        return {
            'analysis': {
                'è¯åˆ¸ä»£ç ': code, 'æ”¶ç›˜ä»·': latest['æ”¶ç›˜'], 'RSI(14)': round(rsi_val, 2),
                'è¶‹åŠ¿': trend_status, 'ä¹–ç¦»ç‡%': round(bias, 2), 'é‡èƒ½æ¯”': round(vol_ratio, 2),
                'æ³¢åŠ¨ç‡%': round(relative_atr, 2), 'æ¨ªç›˜å¤©æ•°': sideways_days, 'ç½‘æ ¼çŠ¶æ€': status,
                'èƒœç‡ç½®ä¿¡åº¦': star, 'å»ºè®®æ“ä½œ': action, 'åŠ ç å€æ•°': weight, 'is_signal': is_buy_signal,
                'current_date': latest['æ—¥æœŸ'] if 'æ—¥æœŸ' in latest else datetime.now().strftime('%Y-%m-%d')
            },
            'history': full_df[['æ—¥æœŸ', 'æ”¶ç›˜']]
        }
    except Exception: return None

def process_backtest(new_data_list, all_hist_map):
    """æ›´æ–°ä¿¡å·è¿½è¸ªè´¦æœ¬"""
    if os.path.exists(TRACKER_FILE):
        tracker = pd.read_csv(TRACKER_FILE)
    else:
        tracker = pd.DataFrame(columns=['ä»£ç ', 'ä¹°å…¥æ—¥æœŸ', 'ä¹°å…¥ä»·', 'T+7æ”¶ç›Š%', 'T+14æ”¶ç›Š%', 'T+20æ”¶ç›Š%', 'T+60æ”¶ç›Š%', 'çŠ¶æ€'])

    # 1. è®°å½•ä»Šæ—¥æ–°ä¿¡å·
    for item in new_data_list:
        if item['is_signal']:
            # åŒä¸€å“ç§10å¤©å†…ä¸é‡å¤è®°å½•ä¹°å…¥ä¿¡å·ï¼Œé˜²æ­¢ä¿¡å·åˆ·å±
            recent = tracker[(tracker['ä»£ç '] == item['è¯åˆ¸ä»£ç '])].tail(1)
            if recent.empty or (datetime.now() - pd.to_datetime(recent['ä¹°å…¥æ—¥æœŸ'].values[0])).days > 10:
                new_row = pd.DataFrame([{
                    'ä»£ç ': item['è¯åˆ¸ä»£ç '], 'ä¹°å…¥æ—¥æœŸ': item['current_date'], 'ä¹°å…¥ä»·': item['æ”¶ç›˜ä»·'],
                    'T+7æ”¶ç›Š%': np.nan, 'T+14æ”¶ç›Š%': np.nan, 'T+20æ”¶ç›Š%': np.nan, 'T+60æ”¶ç›Š%': np.nan, 'çŠ¶æ€': 'æŒæœ‰ä¸­'
                }])
                tracker = pd.concat([tracker, new_row], ignore_index=True)

    # 2. éå†è´¦æœ¬ï¼Œç”¨æœ€æ–°å†å²æ•°æ®åˆ·æ–°æ”¶ç›Š
    for idx, row in tracker.iterrows():
        code = str(row['ä»£ç ']).zfill(6)
        if code in all_hist_map:
            h_df = all_hist_map[code].copy()
            h_df['æ—¥æœŸ'] = pd.to_datetime(h_df['æ—¥æœŸ'])
            buy_date = pd.to_datetime(row['ä¹°å…¥æ—¥æœŸ'])
            
            # è·å–ä¹°å…¥æ—¥ä¹‹åçš„æ‰€æœ‰æ•°æ®
            future_prices = h_df[h_df['æ—¥æœŸ'] > buy_date].copy()
            if not future_prices.empty:
                for t in [7, 14, 20, 60]:
                    col = f'T+{t}æ”¶ç›Š%'
                    if pd.isna(row[col]) and len(future_prices) >= t:
                        p_t = future_prices.iloc[t-1]['æ”¶ç›˜']
                        tracker.at[idx, col] = round((p_t - row['ä¹°å…¥ä»·']) / row['ä¹°å…¥ä»·'] * 100, 2)
                
                if len(future_prices) >= 60:
                    tracker.at[idx, 'çŠ¶æ€'] = 'å·²ç»“é¡¹'

    tracker.to_csv(TRACKER_FILE, index=False, encoding='utf-8-sig')
    return tracker

def main():
    # --- åŠ è½½åˆ—è¡¨ ---
    target_file = None
    for f in [ETF_LIST_FILE, ETF_LIST_FILE.replace('.xlsx', '.csv')]:
        if os.path.exists(f): target_file = f; break
    if not target_file: return

    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file, engine='openpyxl')
        else: name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    # --- å¹¶è¡Œæ‰§è¡Œ ---
    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸš€ Alpha Hunter V5 å¯åŠ¨... æ­£åœ¨åˆ†æå¹¶å›æµ‹ {len(csv_files)} ä¸ªå“ç§")
    with Pool(cpu_count()) as p:
        raw_results = p.map(analyze_fund, csv_files)
    
    analysis_results = [r['analysis'] for r in raw_results if r and r['analysis']['è¯åˆ¸ä»£ç '] in name_map]
    hist_map = {r['analysis']['è¯åˆ¸ä»£ç ']: r['history'] for r in raw_results if r}
    
    if not analysis_results: return

    # --- æ›´æ–°è´¦æœ¬ä¸èƒœç‡ç»Ÿè®¡ ---
    tracker_df = process_backtest(analysis_results, hist_map)
    
    # --- è¾“å‡ºæŠ¥è¡¨ ---
    final_df = pd.DataFrame(analysis_results)
    final_df['è¯åˆ¸ç®€ç§°'] = final_df['è¯åˆ¸ä»£ç '].apply(lambda x: name_map[x])
    cols = ['è¯åˆ¸ä»£ç ', 'è¯åˆ¸ç®€ç§°', 'æ”¶ç›˜ä»·', 'RSI(14)', 'è¶‹åŠ¿', 'ä¹–ç¦»ç‡%', 'é‡èƒ½æ¯”', 'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ']
    final_df = final_df[cols].sort_values(by=['èƒœç‡ç½®ä¿¡åº¦', 'RSI(14)'], ascending=[False, True])

    # ä¿å­˜ä»Šæ—¥æ‰«æç»“æœ
    now = datetime.now()
    os.makedirs(now.strftime('%Y/%m'), exist_ok=True)
    save_path = os.path.join(now.strftime('%Y/%m'), f"alpha_v5_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')

    print(f"\nâœ… ä»Šæ—¥æ‰«æå®Œæˆ: {save_path}")
    print("-" * 100)
    print(final_df.head(10))

    # æ‰“å°èƒœç‡ç®€æŠ¥
    print("\nğŸ“ˆ å†å²ä¿¡å·èƒœç‡éªŒè¯ (signal_tracker.csv):")
    for t in [7, 14, 20, 60]:
        col = f'T+{t}æ”¶ç›Š%'
        valid = tracker_df[tracker_df[col].notna()]
        if not valid.empty:
            wr = (valid[col] > 0).sum() / len(valid) * 100
            avg = valid[col].mean()
            print(f" >> {col}: æ ·æœ¬æ•° {len(valid)}, èƒœç‡ {wr:.1f}%, å¹³å‡æ”¶ç›Š {avg:.2f}%")
        else:
            print(f" >> {col}: æ ·æœ¬ä¸è¶³ï¼Œç­‰å¾…åç»­æ•°æ®åˆ·æ–°...")

if __name__ == "__main__":
    main()
