import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# æˆ˜æ³•è¯´æ˜ï¼šAlpha Hunter V3 èƒ½é‡è¶‹åŠ¿ç½‘æ ¼å…¨èƒ½ç‰ˆ
# æ•´åˆåŠŸèƒ½ï¼š
# 1. [ç»å…¸ç½‘æ ¼] MA20ä¹–ç¦» + RSIè¶…å– + 5æ˜Ÿé‡‘åº•åˆ¤å®š
# 2. [è¶‹åŠ¿é˜²æŠ¤] MA60ç”Ÿå‘½çº¿è¿‡æ»¤ï¼ŒåŒºåˆ†å¤šå¤´/ç©ºå¤´å¸‚åœº
# 3. [é‡ä»·ä¾¦æµ‹] 5æ—¥/20æ—¥é‡èƒ½æ¯”ï¼Œè¯†åˆ«ç¼©é‡è¯±å¤šä¸æ”¾é‡æ€è·Œ
# 4. [åŠ¨æ€é€‚é…] ATRè‡ªé€‚åº”æ³¢åŠ¨ç‡ï¼Œè‡ªåŠ¨è°ƒæ•´æ¨ªç›˜åˆ¤å®šæ ‡å‡†
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        # è¯»å– 120 å¤©æ•°æ®ç¡®ä¿ MA60 å’Œ ATR è®¡ç®—å‡†ç¡®
        df = pd.read_csv(file_path, encoding='utf-8-sig').tail(120)
        if len(df) < 60: return None
        df.columns = [c.strip() for c in df.columns]
        
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        vol_series = df['æˆäº¤é¢']
        
        # --- [1. æµåŠ¨æ€§ä¸åŸºç¡€è¿‡æ»¤] ---
        turnover_raw = latest.get('æ¢æ‰‹ç‡', 0)
        try:
            turnover = float(str(turnover_raw).replace('%', ''))
        except:
            turnover = 0
        if latest['æˆäº¤é¢'] < 10000000 or turnover < 0.1: return None

        # --- [2. è®¡ç®—æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡] ---
        # å‡çº¿ç³»ç»Ÿ
        ma20_s = close_series.rolling(20).mean()
        ma60_s = close_series.rolling(60).mean()
        ma20, ma60 = ma20_s.iloc[-1], ma60_s.iloc[-1]
        
        # ä¹–ç¦»ç‡ä¸ RSI
        bias = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        rsi_val = calculate_rsi(close_series).iloc[-1]
        
        # ATR åŠ¨æ€æ³¢åŠ¨ç‡ (ç”¨äºè‡ªé€‚åº”æ¨ªç›˜åˆ¤å®š)
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        atr = high_low.rolling(14).mean().iloc[-1]
        relative_atr = (atr / latest['æ”¶ç›˜']) * 100
        
        # é‡èƒ½ç³»ç»Ÿ
        vol_ma5 = vol_series.tail(5).mean()
        vol_ma20 = vol_series.tail(20).mean()
        vol_ratio = vol_ma5 / (vol_ma20 + 1e-9)

        # --- [3. æ¨ªç›˜é€»è¾‘ - åŠ¨æ€é˜ˆå€¼ç‰ˆ] ---
        # æ³¢åŠ¨ç‡å¤§çš„å“ç§é˜ˆå€¼é«˜ï¼Œå°çš„åˆ™ä½
        dynamic_threshold = max(0.018, relative_atr * 0.5 / 100)
        is_sideways = ((close_series - ma20_s) / ma20_s).abs() < dynamic_threshold
        sideways_days = 0
        for val in reversed(is_sideways.values):
            if val: sideways_days += 1
            else: break

        # --- [4. çŠ¶æ€ç»¼åˆåˆ¤å®šç³»ç»Ÿ] ---
        trend_status = "å¤šå¤´æ’åˆ—" if ma20 > ma60 else "ç©ºå¤´æ’åˆ—"
        
        # æ¨ªç›˜æ€§è´¨åˆ¤å®š
        sideways_type = "åŠ¨æ€æ³¢åŠ¨"
        if sideways_days >= 3:
            slope = (ma20_s.iloc[-1] - ma20_s.iloc[-5]) / 5
            if bias < 0.5 and slope <= 0: sideways_type = "ä½ä½ç­‘åº•âœ…"
            elif bias > 2.0: sideways_type = "é«˜ä½æ´¾å‘âš ï¸"
            else: sideways_type = "ä¸­ç»§æ•´ç†"

        # æ ¸å¿ƒé€»è¾‘ï¼šé‡ä»·èƒŒç¦»æ£€æµ‹
        is_divergence = (latest['æ”¶ç›˜'] > ma20) and (vol_ratio < 0.85)

        # é»˜è®¤ç½‘æ ¼çŠ¶æ€
        status, action, weight, star = "æ­£å¸¸éœ‡è¡", "å¸¸è§„ç½‘æ ¼", "1.0x", "â˜…â˜…â˜…â˜†â˜†"

        # é€»è¾‘ Aï¼šé‡‘åº•ä¸è¶…å–åˆ¤å®š (ä¹°ç‚¹)
        if rsi_val < 38:
            status, star = "ğŸ”¥æœºä¼šåŒº", "â˜…â˜…â˜…â˜…â˜†"
            action = "åˆ†æ‰¹è¡¥ä»“"
            if rsi_val < 32:
                status, action, weight = "ğŸš¨è¶…å–åŠ ç ", "æš‚åœå–å‡º/ç§¯æä¹°å…¥", "1.5x"
                # ç»ˆæé‡‘åº•ï¼šä¸¥é‡è´Ÿä¹–ç¦» + æ”¾é‡
                if vol_ratio > 1.15 and bias < -4.5:
                    status, star, action, weight = "ğŸ’äº”æ˜Ÿé‡‘åº•", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›ä¹°å…¥", "2.0x"
        
        # é€»è¾‘ Bï¼šé«˜ä½ä¸èƒŒç¦»é£é™© (å–ç‚¹/é˜²å®ˆ)
        elif rsi_val > 70 or is_divergence:
            if is_divergence:
                status, star, action = "ğŸš«ç¼©é‡è¯±å¤š", "â˜…â˜…â˜†â˜†â˜†", "åœæ­¢ä¹°å…¥/ä»…å–å‡º"
            else:
                status, star, action = "âš ï¸é«˜ä½è¶…ä¹°", "â˜…â˜…â˜†â˜†â˜†", "ç½‘æ ¼å‡é‡/æ­¢ç›ˆ"
        
        # é€»è¾‘ Cï¼šå¤šå¤´çªç ´åˆ¤å®š
        elif trend_status == "å¤šå¤´æ’åˆ—" and 0 < bias < 2.5 and sideways_days >= 4:
            status, star, action = "ğŸš€è“„åŠ¿çªç ´", "â˜…â˜…â˜…â˜…â˜†", "æŒä»“å¾…æ¶¨/ç½‘æ ¼ä¸Šç§»"

        # --- [5. è¿‡æ»¤å™¨ï¼šè¿‡æ»¤æ‰æ— æ³¢åŠ¨çš„æ­»é±¼] ---
        avg_amp = df['æŒ¯å¹…'].tail(20).mean()
        if avg_amp < 1.0: return None 

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'è¯åˆ¸ä»£ç ': code,
            'æ”¶ç›˜ä»·': latest['æ”¶ç›˜'],
            'RSI(14)': round(rsi_val, 2),
            'è¶‹åŠ¿': trend_status,
            'ä¹–ç¦»ç‡%': round(bias, 2),
            'é‡èƒ½æ¯”': round(vol_ratio, 2),
            'æ³¢åŠ¨ç‡%': round(relative_atr, 2),
            'æ¨ªç›˜å¤©æ•°': sideways_days,
            'æ¨ªç›˜æ€§è´¨': sideways_type,
            'ç½‘æ ¼çŠ¶æ€': status,
            'èƒœç‡ç½®ä¿¡åº¦': star,
            'å»ºè®®æ“ä½œ': action,
            'åŠ ç å€æ•°': weight,
            'æˆäº¤é¢(ä¸‡)': round(latest['æˆäº¤é¢'] / 10000, 2),
            '20æ—¥å‡æŒ¯å¹…%': round(avg_amp, 2)
        }
    except Exception: return None

def main():
    # æŸ¥æ‰¾ ETF åˆ—è¡¨æ–‡ä»¶
    target_file = None
    for f in [ETF_LIST_FILE, ETF_LIST_FILE.replace('.xlsx', '.csv')]:
        if os.path.exists(f):
            target_file = f
            break
    if not target_file:
        print("âŒ æ‰¾ä¸åˆ° ETF åˆ—è¡¨æ–‡ä»¶")
        return

    # åŠ è½½åç§°æ˜ å°„
    try:
        if target_file.endswith('.xlsx'):
            name_df = pd.read_excel(target_file, engine='openpyxl')
        else:
            name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except Exception as e:
        print(f"âŒ åˆ—è¡¨è¯»å–å¤±è´¥: {e}")
        return

    # å¹¶è¡Œåˆ†æ
    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸ” æ­£åœ¨æ·±åº¦æ‰«æ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        results = p.map(analyze_fund, csv_files)
    
    valid = [r for r in results if r and r['è¯åˆ¸ä»£ç '] in name_map]
    if not valid:
        print("ğŸ’¡ å½“å‰å¸‚åœºæœªåŒ¹é…åˆ°é«˜èƒœç‡ä¿¡å·ï¼Œå»ºè®®ç©ºä»“ç­‰å¾…ã€‚")
        return

    final_df = pd.DataFrame(valid)
    final_df['è¯åˆ¸ç®€ç§°'] = final_df['è¯åˆ¸ä»£ç '].apply(lambda x: name_map[x])
    
    # å­—æ®µé¡ºåºæ’åˆ—
    cols = ['è¯åˆ¸ä»£ç ', 'è¯åˆ¸ç®€ç§°', 'æ”¶ç›˜ä»·', 'RSI(14)', 'è¶‹åŠ¿', 'ä¹–ç¦»ç‡%', 'é‡èƒ½æ¯”', 'æ³¢åŠ¨ç‡%', 
            'æ¨ªç›˜å¤©æ•°', 'æ¨ªç›˜æ€§è´¨', 'ç½‘æ ¼çŠ¶æ€', 'èƒœç‡ç½®ä¿¡åº¦', 'å»ºè®®æ“ä½œ', 'åŠ ç å€æ•°', 'æˆäº¤é¢(ä¸‡)', '20æ—¥å‡æŒ¯å¹…%']
    
    # æ ¸å¿ƒæ’åºï¼šä¼˜å…ˆå±•ç¤ºé«˜ç½®ä¿¡åº¦æ ‡çš„
    final_df = final_df[cols].sort_values(
        by=['èƒœç‡ç½®ä¿¡åº¦', 'RSI(14)'], 
        ascending=[False, True]
    )
    
    # ä¿å­˜ç»“æœ
    now = datetime.now()
    os.makedirs(now.strftime('%Y/%m'), exist_ok=True)
    save_path = os.path.join(now.strftime('%Y/%m'), f"alpha_hunter_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… æ‰«æå®Œæˆï¼æŠ¥å‘Šå·²ç”Ÿæˆï¼š{save_path}")
    print("-" * 50)
    print(final_df[['è¯åˆ¸ç®€ç§°', 'ç½‘æ ¼çŠ¶æ€', 'ç½®ä¿¡åº¦', 'æ“ä½œæŒ‡ä»¤', 'é‡èƒ½æ¯”']].head(10))

if __name__ == "__main__":
    main()
