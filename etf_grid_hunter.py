import pandas as pd
import os
import glob
import numpy as np
from datetime import datetime
from multiprocessing import Pool, cpu_count

# ==============================================================================
# è„šæœ¬è¯´æ˜ï¼šAlpha Hunter ç»ˆæå®æˆ˜ç‰ˆ (V5.1 ç¨³å®šç‰ˆ)
# ä¿®å¤ï¼šè§£å†³é¦–æ¬¡è¿è¡Œè´¦æœ¬åˆ—ååŒ¹é…å¯¼è‡´çš„ KeyError æŠ¥é”™
# åŠŸèƒ½ï¼šå…¨è‡ªåŠ¨é‡ä»·æ‰«æ + å†å²èƒœç‡è®°è´¦ + å¤§ç™½è¯è¯Šæ–­
# ==============================================================================

DATA_DIR = 'fund_data'
ETF_LIST_FILE = 'ETFåˆ—è¡¨.xlsx' 
TRACKER_FILE = 'signal_tracker.csv' 

def calculate_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

def analyze_fund(file_path):
    try:
        full_df = pd.read_csv(file_path, encoding='utf-8-sig')
        if len(full_df) < 60: return None
        full_df.columns = [c.strip() for c in full_df.columns]
        
        df = full_df.tail(120).copy()
        latest = df.iloc[-1]
        close_series = df['æ”¶ç›˜']
        vol_series = df['æˆäº¤é¢']
        
        ma20_s = close_series.rolling(20).mean()
        ma60_s = close_series.rolling(60).mean()
        ma20, ma60 = ma20_s.iloc[-1], ma60_s.iloc[-1]
        
        dist_pct = (latest['æ”¶ç›˜'] - ma20) / ma20 * 100
        temp = calculate_rsi(close_series).iloc[-1]
        pop = vol_series.tail(5).mean() / (vol_series.tail(20).mean() + 1e-9)
        
        high_low = df['æœ€é«˜'] - df['æœ€ä½']
        flex = (high_low.rolling(14).mean().iloc[-1] / latest['æ”¶ç›˜']) * 100

        env = "é¡ºé£å±€(å¼º)" if ma20 > ma60 else "é€†é£å±€(å¼±)"
        
        sideways_limit = max(0.018, flex * 0.5 / 100)
        is_boring = ((close_series - ma20_s) / ma20_s).abs() < sideways_limit
        boring_days = 0
        for val in reversed(is_boring.values):
            if val: boring_days += 1
            else: break
            
        fake_up = (latest['æ”¶ç›˜'] > ma20) and (pop < 0.8)
        
        desc, act, multi, star = "æ­£å¸¸æ³¢åŠ¨", "è¯¥ä¹°ä¹°è¯¥å–å–", "1.0x", "â˜…â˜…â˜…â˜†â˜†"
        is_signal = False 

        if temp < 38:
            desc, star, is_signal = "ğŸ”¥è·Œé€äº†", "â˜…â˜…â˜…â˜…â˜†", True
            act = "å¯ä»¥åˆ†æ‰¹ä¹°"
            if temp < 32:
                desc, act, multi = "ğŸš¨æåº¦å†°ç‚¹", "åªä¹°ä¸å–/å¤§èƒ†åŠ ä»“", "1.5x"
                if pop > 1.15 and dist_pct < -4.5:
                    desc, star, act, multi = "ğŸ’é»„é‡‘å‘", "â˜…â˜…â˜…â˜…â˜…", "å…¨åŠ›æ¡é’±", "2.0x"
        elif temp > 70 or fake_up:
            star = "â˜…â˜…â˜†â˜†â˜†"
            if fake_up:
                desc, act = "ğŸš«è™šå‡ç¹è£", "åˆ«è¿½ï¼å°å¿ƒè¢«å¥—"
            else:
                desc, act = "âš ï¸å¤ªçƒ«äº†", "è§å¥½å°±æ”¶/åˆ†æ‰¹ç¦»åœº"
        elif env == "é¡ºé£å±€(å¼º)" and 0 < dist_pct < 2.5 and boring_days >= 4:
            desc, star, act = "ğŸš€è¦èµ·é£", "â˜…â˜…â˜…â˜…â˜†", "æ‹¿ç¨³äº†ç­‰æ¶¨"

        code = os.path.basename(file_path).replace('.csv', '')
        return {
            'analysis': {
                'ä»£ç ': code, 'ç°ä»·': latest['æ”¶ç›˜'], 'æƒ…ç»ªæ¸©åº¦': round(temp, 1),
                'å½“å‰ç¯å¢ƒ': env, 'ç¦»å®¶è·ç¦»%': round(dist_pct, 2), 'äººæ°”å€¼': round(pop, 2),
                'æ³¢åŠ¨å¼¹æ€§%': round(flex, 2), 'ç£¨æ´‹å·¥å¤©æ•°': boring_days, 'å¸‚åœºè¯Šæ–­': desc,
                'ç½®ä¿¡åº¦': star, 'æ“ä½œå»ºè®®': act, 'åŠ ä»“å€æ•°': multi, 'is_signal': is_signal,
                'date': latest['æ—¥æœŸ'] if 'æ—¥æœŸ' in latest else datetime.now().strftime('%Y-%m-%d')
            },
            'history': full_df[['æ—¥æœŸ', 'æ”¶ç›˜']]
        }
    except Exception: return None

def process_backtest(new_data_list, all_hist_map):
    # å®šä¹‰åˆ—åæ¨¡æ¿ï¼Œç¡®ä¿åç»­è®¿é—®ä¸€è‡´
    columns = ['ä»£ç ', 'å…¥åœºæ—¥æœŸ', 'ä¹°å…¥ä»·', '7å¤©åæ”¶ç›Š%', '14å¤©åæ”¶ç›Š%', '20å¤©åæ”¶ç›Š%', '60å¤©åæ”¶ç›Š%', 'çŠ¶æ€']
    
    if os.path.exists(TRACKER_FILE):
        try:
            tracker = pd.read_csv(TRACKER_FILE)
            # ç¡®ä¿åˆ—åä¸€è‡´æ€§
            for col in columns:
                if col not in tracker.columns: tracker[col] = np.nan
        except:
            tracker = pd.DataFrame(columns=columns)
    else:
        tracker = pd.DataFrame(columns=columns)

    # 1. è®°å½•ä»Šæ—¥æ–°ä¿¡å·
    for item in new_data_list:
        if item['is_signal']:
            recent = tracker[(tracker['ä»£ç '] == item['ä»£ç '])].tail(1)
            # 10å¤©å†…ä¸é‡å¤è®°å½•åŒä¸€å“ç§
            can_add = True
            if not recent.empty:
                last_date = pd.to_datetime(recent['å…¥åœºæ—¥æœŸ'].values[0])
                if (datetime.now() - last_date).days < 10:
                    can_add = False
            
            if can_add:
                new_row = pd.DataFrame([{c: np.nan for c in columns}])
                new_row['ä»£ç '] = item['ä»£ç ']
                new_row['å…¥åœºæ—¥æœŸ'] = item['date']
                new_row['ä¹°å…¥ä»·'] = item['ç°ä»·']
                new_row['çŠ¶æ€'] = 'æŒæœ‰ä¸­'
                tracker = pd.concat([tracker, new_row], ignore_index=True)

    # 2. åˆ·æ–°æ”¶ç›Šç‡
    for idx, row in tracker.iterrows():
        code = str(row['ä»£ç ']).zfill(6)
        if code in all_hist_map:
            h_df = all_hist_map[code].copy()
            h_df['æ—¥æœŸ'] = pd.to_datetime(h_df['æ—¥æœŸ'])
            buy_dt = pd.to_datetime(row['å…¥åœºæ—¥æœŸ'])
            future = h_df[h_df['æ—¥æœŸ'] > buy_dt].copy()
            if not future.empty:
                for t in [7, 14, 20, 60]:
                    col = f'{t}å¤©åæ”¶ç›Š%'
                    if pd.isna(row[col]) and len(future) >= t:
                        p_t = future.iloc[t-1]['æ”¶ç›˜']
                        tracker.at[idx, col] = round((p_t - row['ä¹°å…¥ä»·']) / row['ä¹°å…¥ä»·'] * 100, 2)
                if len(future) >= 60: tracker.at[idx, 'çŠ¶æ€'] = 'å·²ç»“é¡¹'

    tracker.to_csv(TRACKER_FILE, index=False, encoding='utf-8-sig')
    return tracker

def main():
    target_file = None
    for f in [ETF_LIST_FILE, ETF_LIST_FILE.replace('.xlsx', '.csv')]:
        if os.path.exists(f): target_file = f; break
    if not target_file: return

    try:
        if target_file.endswith('.xlsx'): name_df = pd.read_excel(target_file, engine='openpyxl')
        else: name_df = pd.read_csv(target_file, encoding='utf-8-sig')
        name_df.columns = [c.strip() for c in name_df.columns]
        name_df['è¯åˆ¸ä»£ç '] = name_df['è¯åˆ¸ä»£ç '].astype(str).str.zfill(6)
        name_map = dict(zip(name_df['è¯åˆ¸ä»£ç '], name_df['è¯åˆ¸ç®€ç§°']))
    except: return

    csv_files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    print(f"ğŸš€ Alpha Hunter å¯åŠ¨ï¼šæ‰«æ {len(csv_files)} ä¸ªå“ç§...")
    with Pool(cpu_count()) as p:
        raw_results = p.map(analyze_fund, csv_files)
    
    analysis_results = [r['analysis'] for r in raw_results if r and r['analysis']['ä»£ç '] in name_map]
    hist_map = {r['analysis']['ä»£ç ']: r['history'] for r in raw_results if r}
    
    if not analysis_results: return
    tracker_df = process_backtest(analysis_results, hist_map)
    
    final_df = pd.DataFrame(analysis_results)
    final_df['ç®€ç§°'] = final_df['ä»£ç '].apply(lambda x: name_map[x])
    cols = ['ä»£ç ', 'ç®€ç§°', 'ç°ä»·', 'æƒ…ç»ªæ¸©åº¦', 'å½“å‰ç¯å¢ƒ', 'å¸‚åœºè¯Šæ–­', 'ç½®ä¿¡åº¦', 'æ“ä½œå»ºè®®', 'äººæ°”å€¼', 'ç£¨æ´‹å·¥å¤©æ•°']
    final_df = final_df[cols].sort_values(by=['ç½®ä¿¡åº¦', 'æƒ…ç»ªæ¸©åº¦'], ascending=[False, True])

    now = datetime.now()
    os.makedirs(now.strftime('%Y/%m'), exist_ok=True)
    save_path = os.path.join(now.strftime('%Y/%m'), f"market_scan_{now.strftime('%Y%m%d')}.csv")
    final_df.to_csv(save_path, index=False, encoding='utf-8-sig')

    print(f"\nâœ… è¯Šæ–­æŠ¥å‘Šå·²ç”Ÿæˆï¼š{save_path}")
    print("-" * 100)
    print(final_df.head(10))

    print("\nğŸ“ˆ å†å²â€œä¹°å…¥â€åçš„è¡¨ç°éªŒè¯:")
    # å¢åŠ å¥å£®æ€§æ£€æŸ¥ï¼Œç¡®ä¿åˆ—å­˜åœ¨
    for t in [7, 14, 20, 60]:
        col = f'{t}å¤©åæ”¶ç›Š%'
        if col in tracker_df.columns:
            # æ˜¾å¼è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œé¿å… object ç±»å‹å¯¼è‡´ notna() å¼‚å¸¸
            valid_vals = pd.to_numeric(tracker_df[col], errors='coerce')
            valid = tracker_df[valid_vals.notna()]
            if not valid.empty:
                wr = (pd.to_numeric(valid[col]) > 0).sum() / len(valid) * 100
                avg = pd.to_numeric(valid[col]).mean()
                print(f" >> ä¹°å…¥{t:2d}å¤©åï¼šæˆåŠŸç‡ {wr:5.1f}%, å¹³å‡èµš {avg:5.2f}% (æ ·æœ¬:{len(valid)}ä¸ª)")
            else:
                print(f" >> ä¹°å…¥{t:2d}å¤©åï¼šè¿˜åœ¨è§‚å¯Ÿä¸­...")
        else:
            print(f" >> ä¹°å…¥{t:2d}å¤©åï¼šåˆ—åå¼‚å¸¸")

if __name__ == "__main__":
    main()
