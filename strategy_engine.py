import os
import glob
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
from multiprocessing import Pool, cpu_count

# ==========================================
# --- 1. æ ¸å¿ƒé”æ­»é£æ§ä¸ç­–ç•¥å‚æ•° ---
# ==========================================
TOTAL_BUDGET_CAP = 10000   # 1ä¸‡æœ¬é‡‘æ€»ä¸Šé™
PORTFOLIO_UNIT = 2000      # å•ç¬”æŠ„åº•é‡‘é¢
STOP_BUY_LOSS_RATIO = -5.0 # ç»„åˆæ€»äºæŸè¶…5%ï¼Œå¼€å¯ç¦ä¹°ä»¤
RETR_WATCH = -10.0         # 10%å›è°ƒä»‹å…¥
RETR_WINDOW = 250          # 250æ—¥å®æˆ˜å‘¨æœŸ
LIQUIDITY_LIMIT = 10000000 # æ—¥å‡æˆäº¤é¢ä½äº1000ä¸‡ä¸å…¥æ± 

# ==========================================
# --- 2. æ˜ å°„é€»è¾‘ï¼šåŠ è½½ ETF åç§° ---
# ==========================================
def load_name_mapping():
    mapping = {}
    try:
        if os.path.exists('ETFåˆ—è¡¨.txt'):
            try:
                df_map = pd.read_csv('ETFåˆ—è¡¨.txt', sep='\t', dtype={'è¯åˆ¸ä»£ç ': str})
            except:
                df_map = pd.read_csv('ETFåˆ—è¡¨.txt', sep='\t', dtype={'è¯åˆ¸ä»£ç ': str}, encoding='gbk')
            for _, row in df_map.iterrows():
                code = str(row['è¯åˆ¸ä»£ç ']).zfill(6)
                mapping[code] = row['è¯åˆ¸ç®€ç§°']
    except Exception as e:
        print(f"åç§°æ˜ å°„åŠ è½½å¤±è´¥: {e}")
    return mapping

NAME_MAP = load_name_mapping()

# ==========================================
# --- 3. å¢å¼ºç‰ˆæŠ€æœ¯æŒ‡æ ‡æ¨¡å— ---
# ==========================================
def calculate_rsi(series, period=6):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss.replace(0, np.nan)
    return 100 - (100 / (1 + rs.fillna(0)))

def check_strong_divergence(df, window=20):
    """
    å¢å¼ºç‰ˆåº•èƒŒç¦»ï¼šä»·æ ¼åˆ›æ–°ä½ï¼ˆä¸”æ¯”å‰ä½è‡³å°‘ä½1%ï¼‰ï¼ŒRSIæ˜¾è‘—å›å‡
    """
    if len(df) < window + 5: return False
    curr_p = df['æ”¶ç›˜'].iloc[-1]
    curr_rsi = df['rsi6'].iloc[-1]
    
    lookback = df.iloc[-(window+1):-1]
    min_idx = lookback['æ”¶ç›˜'].idxmin()
    min_p = lookback.loc[min_idx, 'æ”¶ç›˜']
    min_rsi = lookback.loc[min_idx, 'rsi6']
    
    # é€»è¾‘è¿‡æ»¤ï¼šå½“å‰ä»·å¿…é¡»è·Œç ´å‰ä½ï¼Œä¸”RSIæ¯”å‰ä½ç‚¹æ—¶çš„RSIé«˜å‡º5ç‚¹ä»¥ä¸Š
    if curr_p < min_p * 0.99 and curr_rsi > min_rsi + 5:
        return True
    return False

# ==========================================
# --- 4. å•æ–‡ä»¶å¤„ç† (åŒæŒ‡æ ‡å…±æŒ¯ç‰ˆ) ---
# ==========================================
def process_file(file_path):
    try:
        try: df = pd.read_csv(file_path, encoding='utf-8')
        except: df = pd.read_csv(file_path, encoding='gbk')
        if 'net_value' in df.columns:
            df = df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
        if 'æ—¥æœŸ' not in df.columns or 'æ”¶ç›˜' not in df.columns: return None

        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)
        if len(df) < 60: return None # å¢åŠ æ ·æœ¬é‡ä»¥æ”¯æŒMA20
        
        if 'æˆäº¤é¢' in df.columns:
            if df['æˆäº¤é¢'].iloc[-5:].mean() < LIQUIDITY_LIMIT: return None

        curr_p = df['æ”¶ç›˜'].iloc[-1]
        prev_p = df['æ”¶ç›˜'].iloc[-2]
        
        # æŒ‡æ ‡è®¡ç®—ï¼šåŒRSI + åŒBIAS + è¶‹åŠ¿çº¿
        df['rsi6'] = calculate_rsi(df['æ”¶ç›˜'], 6)
        df['rsi14'] = calculate_rsi(df['æ”¶ç›˜'], 14)
        df['ma6'] = df['æ”¶ç›˜'].rolling(window=6).mean()
        df['ma20'] = df['æ”¶ç›˜'].rolling(window=20).mean()
        df['ma10'] = df['æ”¶ç›˜'].rolling(window=10).mean() # ç”¨äºæ­¢ç›ˆè¶‹åŠ¿
        df['bias6'] = ((df['æ”¶ç›˜'] - df['ma6']) / df['ma6']) * 100
        df['bias20'] = ((df['æ”¶ç›˜'] - df['ma20']) / df['ma20']) * 100
        df['max_high'] = df['æ”¶ç›˜'].rolling(window=RETR_WINDOW).max()
        df['retr'] = ((df['æ”¶ç›˜'] - df['max_high']) / df['max_high']) * 100
        
        df['in_watch'] = df['retr'] <= RETR_WATCH
        df['persist_days'] = df['in_watch'].groupby((df['in_watch'] != df['in_watch'].shift()).cumsum()).cumcount() + 1
        df.loc[~df['in_watch'], 'persist_days'] = 0

        curr = df.iloc[-1]
        code = os.path.splitext(os.path.basename(file_path))[0].zfill(6)
        name = NAME_MAP.get(code, "æœªçŸ¥å“ç§")
        
        if curr['in_watch']:
            score = 1
            divergence = check_strong_divergence(df)
            # RSIå…±æŒ¯ï¼šçŸ­æœŸè¶…å– + ä¸­æœŸä¸è¶…ä¹°
            if curr['rsi6'] < 30 and curr['rsi14'] < 40: score += 2
            # BIASå…±æŒ¯ï¼šçŸ­æœŸåŠä¸­æœŸå‡å‡ºç°ä¹–ç¦»
            if curr['bias6'] < -5 and curr['bias20'] < -7: score += 2
            # å¼ºåŒ–èƒŒç¦»åŠ åˆ†
            if divergence: score += 2
            
            risk_level = "æ­£å¸¸"
            if divergence: risk_level = "ğŸ“ˆå¼ºåŠ›åº•èƒŒç¦»"
            elif curr['rsi6'] > 50: risk_level = "ğŸš©å‡æ‘”é™·é˜±"
                
            return {
                'date': str(curr['æ—¥æœŸ']).split(' ')[0],
                'fund_code': code,
                'åç§°': name,
                'è¯„åˆ†': score,
                'æŒç»­å¤©æ•°': int(curr['persist_days']),
                'é£é™©é¢„è­¦': risk_level,
                'å›æ’¤%': round(curr['retr'], 2),
                'RSI6': round(curr['rsi6'], 2),
                'BIAS20': round(curr['bias20'], 2),
                'price': round(curr['æ”¶ç›˜'], 4),
                'ma5_trend': "UP" if curr['ma6'] > df['ma6'].iloc[-2] else "DOWN"
            }
    except: return None

# ==========================================
# --- 5. ç›ˆäºç»Ÿè®¡ä¸è¶‹åŠ¿æ­¢ç›ˆé€»è¾‘ ---
# ==========================================
def get_performance_stats():
    history_files = glob.glob('202*/**/*.csv', recursive=True)
    perf_list = []
    for h_file in history_files:
        if 'perf' in h_file: continue
        try:
            h_df = pd.read_csv(h_file)
            for _, sig in h_df.iterrows():
                code = str(sig['fund_code']).zfill(6)
                raw_path = f'fund_data/{code}.csv'
                if not os.path.exists(raw_path): continue
                try: raw_df = pd.read_csv(raw_path, encoding='utf-8')
                except: raw_df = pd.read_csv(raw_path, encoding='gbk')
                if 'net_value' in raw_df.columns: raw_df = raw_df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
                raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                
                idx_list = raw_df[raw_df['æ—¥æœŸ'] == str(sig['date'])].index
                if not idx_list.empty:
                    curr_idx = idx_list[0]
                    signal_price = sig['price']
                    after_signal_df = raw_df.iloc[curr_idx:].copy()
                    after_signal_df['ma5'] = after_signal_df['æ”¶ç›˜'].rolling(window=5).mean()
                    after_signal_df['ma10'] = after_signal_df['æ”¶ç›˜'].rolling(window=10).mean()
                    
                    latest = after_signal_df.iloc[-1]
                    max_profit = (after_signal_df['æ”¶ç›˜'].max() - signal_price) / signal_price * 100
                    total_hold_change = (latest['æ”¶ç›˜'] - signal_price) / signal_price * 100
                    
                    # è¶‹åŠ¿åˆ¤å®šï¼š5æ—¥çº¿æ­»å‰10æ—¥çº¿
                    is_dead_cross = latest['ma5'] < latest['ma10'] and len(after_signal_df) > 5
                    
                    perf_list.append({
                        'æ—¥æœŸ': sig['date'], 'ä»£ç ': code, 'åç§°': NAME_MAP.get(code, "æœªçŸ¥"),
                        'è¯„åˆ†': sig.get('è¯„åˆ†', 1), 'æœ€æ–°ä»·': round(latest['æ”¶ç›˜'], 4), 
                        'æœ€é«˜æµ®ç›ˆ%': round(max_profit, 2), 'æ€»ç›ˆäº%': round(total_hold_change, 2),
                        'çŠ¶æ€': "âœ…è¶‹åŠ¿å‘ä¸Š" if not is_dead_cross else "ğŸš¨è¶‹åŠ¿èµ°å¼±",
                        'æ­»å‰': "YES" if is_dead_cross else "NO"
                    })
        except: continue
    return pd.DataFrame(perf_list)

# ==========================================
# --- 6. æœ€ç»ˆå†³ç­–æŠ¥å‘Šç”Ÿæˆ ---
# ==========================================
def update_readme(current_res, perf_df):
    now_bj = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')
    content = f"# ğŸ¤– ETF/åŸºé‡‘ ç­–ç•¥é›·è¾¾ (ç®—æ³•å¢å¼ºç‰ˆ)\n\n> æœ€åæ›´æ–°: `{now_bj}`\n\n"
    content += "### ğŸš© æˆ˜æ³•é“å¾‹ï¼š\n- **åŒRSIå…±æŒ¯**ï¼šRSI6 < 30 ä¸” RSI14 < 40 ç¡®è®¤ä¸ºçœŸåº•éƒ¨ã€‚\n- **è¶‹åŠ¿æ­¢ç›ˆ**ï¼šæµ®ç›ˆ > 5% åï¼Œå‡ºç° **5æ—¥çº¿æ­»å‰10æ—¥çº¿** æˆ– **åˆ©æ¶¦å›å3%** å¼ºåˆ¶ç¦»åœºã€‚\n\n"
    
    if not perf_df.empty:
        active = perf_df.drop_duplicates(subset=['ä»£ç '])
        total_p = (active['æ€»ç›ˆäº%'] / 100 * PORTFOLIO_UNIT).sum()
        avg_r = (total_p / (len(active)*PORTFOLIO_UNIT)) * 100 if len(active)>0 else 0
        content += f"## ğŸ’° å®æˆ˜é£æ§ç›˜å£\n> **æ€»ç›ˆäº**: `Â¥{total_p:.2f} ({avg_r:+.2f}%)` | **é£æ§**: `{'ğŸ›¡ï¸å®‰å…¨' if avg_r > STOP_BUY_LOSS_RATIO else 'âŒåœä¹°'}`\n\n"

    content += "## ğŸ¯ å®æ—¶ä¿¡å· (åŒæŒ‡æ ‡å…±æŒ¯ç‰ˆ)\n"
    if current_res:
        df = pd.DataFrame(current_res).sort_values(['è¯„åˆ†', 'å›æ’¤%'], ascending=[False, True])
        content += df[['date', 'fund_code', 'åç§°', 'è¯„åˆ†', 'é£é™©é¢„è­¦', 'å›æ’¤%', 'RSI6', 'BIAS20', 'price']].to_markdown(index=False) + "\n\n"

    content += "## ğŸ”¥ æ´»è·ƒä¹°ç‚¹ (è¶‹åŠ¿è·Ÿè¸ª)\n"
    if not perf_df.empty:
        def decide_sell(row):
            if row['æ€»ç›ˆäº%'] >= 5.0 and row['æ­»å‰'] == "YES": return "ğŸš¨ è¶‹åŠ¿åè½¬ï¼Œæ¸…ä»“ï¼"
            if row['æœ€é«˜æµ®ç›ˆ%'] > 8.0 and row['æ€»ç›ˆäº%'] < (row['æœ€é«˜æµ®ç›ˆ%'] - 3.0): return "ğŸš¨ åˆ©æ¶¦å›åï¼Œç»“è´¦"
            return row['çŠ¶æ€']
        
        perf_df['æ“ä½œå»ºè®®'] = perf_df.apply(decide_sell, axis=1)
        content += perf_df[['æ—¥æœŸ', 'ä»£ç ', 'åç§°', 'è¯„åˆ†', 'æœ€é«˜æµ®ç›ˆ%', 'æ€»ç›ˆäº%', 'æ“ä½œå»ºè®®']].to_markdown(index=False) + "\n\n"

    with open('README.md', 'w', encoding='utf-8') as f: f.write(content)

# ==========================================
# --- 7. ä¸»ç¨‹åºå…¥å£ ---
# ==========================================
def main():
    if not os.path.exists('fund_data'): return
    files = glob.glob('fund_data/*.csv')
    with Pool(cpu_count()) as p:
        results = [r for r in p.map(process_file, files) if r is not None]
    if results:
        now = datetime.now()
        folder = now.strftime('%Y/%m')
        os.makedirs(folder, exist_ok=True)
        pd.DataFrame(results).to_csv(f"{folder}/sig_{now.strftime('%d_%H%M%S')}.csv", index=False)
    update_readme(results, get_performance_stats())

if __name__ == "__main__":
    main()