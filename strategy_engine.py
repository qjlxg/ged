import os
import glob
import pandas as pd
from datetime import datetime
from multiprocessing import Pool, cpu_count

# --- æ ¸å¿ƒå‚æ•° (ç»å¯¹ä¿æŒä¸å˜) ---
RETR_WATCH = -10.0     
RSI_LOW = 30           
BIAS_LOW = -5.0        

def calculate_rsi(series, period=6):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    return 100 - (100 / (1 + (gain / loss)))

def process_file(file_path):
    try:
        try: df = pd.read_csv(file_path, encoding='utf-8')
        except: df = pd.read_csv(file_path, encoding='gbk')
        if 'net_value' in df.columns:
            df = df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)
        
        df['rsi'] = calculate_rsi(df['æ”¶ç›˜'], 6)
        df['ma6'] = df['æ”¶ç›˜'].rolling(window=6).mean()
        df['bias'] = ((df['æ”¶ç›˜'] - df['ma6']) / df['ma6']) * 100
        df['max_30'] = df['æ”¶ç›˜'].rolling(window=30).max()
        df['retr'] = ((df['æ”¶ç›˜'] - df['max_30']) / df['max_30']) * 100
        
        curr = df.iloc[-1]
        code = os.path.splitext(os.path.basename(file_path))[0]
        
        if curr['retr'] <= RETR_WATCH:
            score = 1
            if curr['rsi'] < RSI_LOW: score += 2
            if curr['bias'] < BIAS_LOW: score += 2
            return {
                'date': str(curr['æ—¥æœŸ']).split(' ')[0],
                'fund_code': code,
                'price': round(curr['æ”¶ç›˜'], 4),
                'å›æ’¤%': round(curr['retr'], 2),
                'RSI': round(curr['rsi'], 2),
                'BIAS': round(curr['bias'], 2),
                'è¯„åˆ†': score,
                'ä¿¡å·': "é‡ç‚¹" if score >= 3 else "è§‚å¯Ÿ"
            }
    except: return None

def get_performance_stats():
    """å‡çº§ï¼šå¢åŠ â€˜è§£å¥—å¤©æ•°â€™ç»Ÿè®¡ï¼Œè¿½è¸ªä¿¡å·è§¦å‘åçš„å›å‡æ—¶é—´"""
    history_files = glob.glob('202*/**/*.csv', recursive=True)
    perf_list = []
    for h_file in history_files:
        if 'perf' in h_file: continue
        try:
            h_df = pd.read_csv(h_file)
            for _, sig in h_df.iterrows():
                code = str(sig['fund_code']).zfill(6)
                raw_path = f'fund_data/{code}.csv'
                if os.path.exists(raw_path):
                    raw_df = pd.read_csv(raw_path)
                    if 'net_value' in raw_df.columns:
                        raw_df = raw_df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
                    raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                    
                    idx_list = raw_df[raw_df['æ—¥æœŸ'] == str(sig['date'])].index
                    if not idx_list.empty:
                        curr_idx = idx_list[0]
                        # 1. è¿½è¸ªçŸ­å‘¨æœŸè¡¨ç° (10å¤©)
                        future_10 = raw_df.iloc[curr_idx+1 : curr_idx+11]
                        
                        # 2. è®¡ç®—å›æœ¬å¤©æ•° (åœ¨ä¿¡å·ä¹‹åçš„æ‰€æœ‰æ•°æ®ä¸­å¯»æ‰¾)
                        recovery_df = raw_df.iloc[curr_idx+1:]
                        back_days = "æœªå›æœ¬"
                        back_idx = recovery_df[recovery_df['æ”¶ç›˜'] >= sig['price']].index
                        if not back_idx.empty:
                            back_days = back_idx[0] - curr_idx
                        
                        if not future_10.empty:
                            max_up = (future_10['æ”¶ç›˜'].max() - sig['price']) / sig['price'] * 100
                            max_down = (future_10['æ”¶ç›˜'].min() - sig['price']) / sig['price'] * 100
                            status = "âœ…åå¼¹ä¸­" if max_up >= 1.0 else "âŒèµ°å¼±" if max_down <= -3.0 else "â³ç£¨åº•ä¸­"
                            
                            perf_list.append({
                                'æ—¥æœŸ': sig['date'], 'ä»£ç ': code,
                                'å›æ’¤%': sig.get('å›æ’¤%', 0),
                                'RSI': sig.get('RSI', 0),
                                'BIAS': sig.get('BIAS', 0),
                                'å‘¨æœŸæœ€é«˜%': round(max_up, 2), 
                                'æœŸé—´æœ€æ·±%': round(max_down, 2),
                                'å›æœ¬å¤©æ•°': back_days, # æ–°å¢åˆ—
                                'è¯„åˆ†': sig.get('è¯„åˆ†', 1), 
                                'ç»“æœ': status
                            })
        except: continue
    return pd.DataFrame(perf_list)

def update_readme(current_res, perf_df):
    now_bj = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    content = f"# ğŸ¤– ETF/åŸºé‡‘ ç­–ç•¥é›·è¾¾ (å®æˆ˜åŠ å¼ºç‰ˆ)\n\n> æœ€åæ›´æ–°: `{now_bj}`\n\n"
    
    if not perf_df.empty:
        win_rate = (len(perf_df[perf_df['ç»“æœ'] == 'âœ…åå¼¹ä¸­']) / len(perf_df)) * 100
        # è®¡ç®—å¹³å‡è§£å¥—æ—¶é—´(ä»…é’ˆå¯¹å·²å›æœ¬çš„)
        recovered = perf_df[perf_df['å›æœ¬å¤©æ•°'] != 'æœªå›æœ¬']
        avg_back = recovered['å›æœ¬å¤©æ•°'].mean() if not recovered.empty else 0
        content += f"## ğŸ“Š ç­–ç•¥æ•ˆç‡ (10æ—¥è¿½è¸ª)\n> **ç»¼åˆèƒœç‡**: `{win_rate:.2f}%` | **å¹³å‡å›æœ¬**: `{avg_back:.1f}å¤©` | **æ ·æœ¬æ•°**: `{len(perf_df)}` \n\n"

    content += "## ğŸ¯ å®æ—¶ç›‘æ§ (å›æ’¤ > 10%)\n"
    if current_res:
        df = pd.DataFrame(current_res).sort_values('è¯„åˆ†', ascending=False)
        content += df.to_markdown(index=False) + "\n\n"
    
    content += "## ğŸ“ˆ å†å²æ•ˆæœå¤ç›˜ (å«è§£å¥—å‘¨æœŸ)\n"
    if not perf_df.empty:
        cols = ['æ—¥æœŸ', 'ä»£ç ', 'å›æ’¤%', 'RSI', 'BIAS', 'å‘¨æœŸæœ€é«˜%', 'æœŸé—´æœ€æ·±%', 'å›æœ¬å¤©æ•°', 'è¯„åˆ†', 'ç»“æœ']
        content += perf_df[cols].tail(25).iloc[::-1].to_markdown(index=False) + "\n"
    
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(content)

def main():
    files = glob.glob('fund_data/*.csv')
    with Pool(cpu_count()) as p:
        results = [r for r in p.map(process_file, files) if r is not None]
    if results:
        now = datetime.now()
        folder = now.strftime('%Y/%m')
        os.makedirs(folder, exist_ok=True)
        pd.DataFrame(results).to_csv(f"{folder}/sig_{now.strftime('%d_%H%M%S')}.csv", index=False)
    perf_df = get_performance_stats()
    update_readme(results, perf_df)

if __name__ == "__main__":
    main()
