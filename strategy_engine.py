import os
import glob
import pandas as pd
from datetime import datetime
from multiprocessing import Pool, cpu_count

# --- æ ¸å¿ƒå‚æ•° (ç»å¯¹ä¸åŠ¨ï¼Œä½œä¸ºå®æˆ˜æ ‡å°º) ---
GRID_GAP = -5.0        
RETR_WATCH = -5.0     
RSI_LOW = 30           
BIAS_LOW = -5.0        

def calculate_rsi(series, period=6):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    return 100 - (100 / (1 + (gain / loss)))

def process_file(file_path):
    try:
        try: df = pd.read_csv(file_path, encoding='utf-8')
        except: df = pd.read_csv(file_path, encoding='gbk')
        if 'net_value' in df.columns:
            df = df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)
        
        # æ ¸å¿ƒæŒ‡æ ‡é€»è¾‘ï¼šä¸¥æ ¼ç»´æŒåŸæ ·
        df['rsi'] = calculate_rsi(df['æ”¶ç›˜'], 6)
        df['ma6'] = df['æ”¶ç›˜'].rolling(window=6).mean()
        df['bias'] = ((df['æ”¶ç›˜'] - df['ma6']) / df['ma6']) * 100
        df['max_30'] = df['æ”¶ç›˜'].rolling(window=30).max()
        df['retr'] = ((df['æ”¶ç›˜'] - df['max_30']) / df['max_30']) * 100
        
        curr = df.iloc[-1]
        code = os.path.splitext(os.path.basename(file_path))[0]
        
        if curr['retr'] <= RETR_WATCH:
            score = 1
            if curr['rsi'] < RSI_LOW: score += 2
            if curr['bias'] < BIAS_LOW: score += 2
            return {
                'date': str(curr['æ—¥æœŸ']).split(' ')[0],
                'fund_code': code,
                'price': round(curr['æ”¶ç›˜'], 4),
                'å›æ’¤%': round(curr['retr'], 2),
                'RSI': round(curr['rsi'], 2),
                'BIAS': round(curr['bias'], 2),
                'è¯„åˆ†': score,
                'ä¿¡å·': "é‡ç‚¹" if score >= 3 else "è§‚å¯Ÿ"
            }
    except: return None

def get_performance_stats():
    """ä»…å‡çº§å¤ç›˜è¡¨ï¼Œå¢åŠ åŸå§‹ç¯å¢ƒæ•°å€¼ï¼Œç”¨äºåç»­åˆ†æ"""
    history_files = glob.glob('202*/**/*.csv', recursive=True)
    perf_list = []
    for h_file in history_files:
        if 'perf' in h_file: continue
        try:
            h_df = pd.read_csv(h_file)
            for _, sig in h_df.iterrows():
                code = str(sig['fund_code']).zfill(6)
                raw_path = f'fund_data/{code}.csv'
                if os.path.exists(raw_path):
                    raw_df = pd.read_csv(raw_path)
                    if 'net_value' in raw_df.columns:
                        raw_df = raw_df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
                    raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                    
                    idx_list = raw_df[raw_df['æ—¥æœŸ'] == str(sig['date'])].index
                    if not idx_list.empty:
                        curr_idx = idx_list[0]
                        # è¿½è¸ªå3æ—¥è¡¨ç°
                        future_df = raw_df.iloc[curr_idx+1 : curr_idx+4]
                        if not future_df.empty:
                            max_up = (future_df['æ”¶ç›˜'].max() - sig['price']) / sig['price'] * 100
                            max_down = (future_df['æ”¶ç›˜'].min() - sig['price']) / sig['price'] * 100
                            
                            status = "âœ…åå¼¹ä¸­" if max_up >= 1.0 else "âŒèµ°å¼±" if max_down <= -3.0 else "â³ç£¨åº•ä¸­"
                            
                            perf_list.append({
                                'æ—¥æœŸ': sig['date'], 'ä»£ç ': code,
                                'å›æ’¤%': sig.get('å›æ’¤%', 0), # è®°å½•è§¦å‘æ—¶çš„åŸå§‹å›æ’¤
                                'RSI': sig.get('RSI', 0),    # è®°å½•è§¦å‘æ—¶çš„åŸå§‹RSI
                                'BIAS': sig.get('BIAS', 0),  # è®°å½•è§¦å‘æ—¶çš„åŸå§‹BIAS
                                'å‘¨æœŸæœ€é«˜%': round(max_up, 2), 
                                'æœŸé—´æœ€æ·±%': round(max_down, 2),
                                'è¯„åˆ†': sig.get('è¯„åˆ†', 1), 
                                'ç»“æœ': status
                            })
        except: continue
    return pd.DataFrame(perf_list)

def update_readme(current_res, perf_df):
    now_bj = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    content = f"# ğŸ¤– ETF/åŸºé‡‘ ç­–ç•¥é›·è¾¾ (å®æˆ˜åŠ å¼ºç‰ˆ)\n\n> æœ€åæ›´æ–°: `{now_bj}`\n\n"
    
    if not perf_df.empty:
        win_rate = (len(perf_df[perf_df['ç»“æœ'] == 'âœ…åå¼¹ä¸­']) / len(perf_df)) * 100
        content += f"## ğŸ“Š ç­–ç•¥æ•ˆç‡ (3æ—¥å†…æœ€é«˜åå¼¹ > 1% æ¦‚ç‡)\n> **å½“å‰ç»¼åˆèƒœç‡**: `{win_rate:.2f}%` | **å›æµ‹æ ·æœ¬**: `{len(perf_df)}` \n\n"

    content += "## ğŸ¯ å®æ—¶ç›‘æ§ (å›æ’¤ > 10%)\n"
    if current_res:
        df = pd.DataFrame(current_res).sort_values('è¯„åˆ†', ascending=False)
        content += df.to_markdown(index=False) + "\n\n"
    
    content += "## ğŸ“ˆ å†å²å®šæŠ•ç‚¹æ•ˆæœè¿½è¸ª (è¯¦ç»†å›æµ‹ç‰ˆ)\n"
    if not perf_df.empty:
        # æŒ‰ä½ çš„è¦æ±‚ï¼Œè¾“å‡ºåŒ…å«åŸå§‹æ•°å€¼çš„è¯¦ç»†è¡¨æ ¼
        cols = ['æ—¥æœŸ', 'ä»£ç ', 'å›æ’¤%', 'RSI', 'BIAS', 'å‘¨æœŸæœ€é«˜%', 'æœŸé—´æœ€æ·±%', 'è¯„åˆ†', 'ç»“æœ']
        content += perf_df[cols].tail(25).iloc[::-1].to_markdown(index=False) + "\n"
    
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(content)

def main():
    files = glob.glob('fund_data/*.csv')
    with Pool(cpu_count()) as p:
        results = [r for r in p.map(process_file, files) if r is not None]
    
    if results:
        now = datetime.now()
        folder = now.strftime('%Y/%m')
        os.makedirs(folder, exist_ok=True)
        pd.DataFrame(results).to_csv(f"{folder}/sig_{now.strftime('%d_%H%M%S')}.csv", index=False)
    
    perf_df = get_performance_stats()
    update_readme(results, perf_df)

if __name__ == "__main__":
    main()
