import os
import glob
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from multiprocessing import Pool, cpu_count

# --- æ ¸å¿ƒå‚æ•° ---
RETR_WINDOW = 250      
RETR_WATCH = -10.0     
RSI_LOW = 30           
BIAS_LOW = -5.0        

def calculate_rsi(series, period=6):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    return 100 - (100 / (1 + (gain / loss)))

def process_file(file_path):
    try:
        try: df = pd.read_csv(file_path, encoding='utf-8')
        except: df = pd.read_csv(file_path, encoding='gbk')
        if 'net_value' in df.columns:
            df = df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)
        
        # è®¡ç®—æŒ‡æ ‡
        df['rsi'] = calculate_rsi(df['æ”¶ç›˜'], 6)
        df['ma6'] = df['æ”¶ç›˜'].rolling(window=6).mean()
        df['bias'] = ((df['æ”¶ç›˜'] - df['ma6']) / df['ma6']) * 100
        df['max_high'] = df['æ”¶ç›˜'].rolling(window=RETR_WINDOW).max()
        df['retr'] = ((df['æ”¶ç›˜'] - df['max_high']) / df['max_high']) * 100
        
        # --- ä¿¡å·æŒç»­æ€§é€»è¾‘ ---
        # æ ‡è®°æ‰€æœ‰ç¬¦åˆå›æ’¤æ¡ä»¶çš„è¡Œ
        df['in_watch'] = df['retr'] <= RETR_WATCH
        # è®¡ç®—è¿ç»­å‡ºç°çš„æ¬¡æ•°
        df['persist_days'] = df['in_watch'].groupby((df['in_watch'] != df['in_watch'].shift()).cumsum()).cumcount() + 1
        df.loc[~df['in_watch'], 'persist_days'] = 0

        curr = df.iloc[-1]
        code = os.path.splitext(os.path.basename(file_path))[0]
        
        if curr['in_watch']:
            score = 1
            if curr['rsi'] < RSI_LOW: score += 2
            if curr['bias'] < BIAS_LOW: score += 2
            
            risk_level = "æ­£å¸¸"
            if curr['rsi'] > 55 and score == 1:
                risk_level = "ğŸš©é«˜é£é™©(é™·é˜±)"
            elif score >= 3:
                risk_level = "âœ…é«˜èƒœç‡åŒº"
                
            return {
                'date': str(curr['æ—¥æœŸ']).split(' ')[0],
                'fund_code': code,
                'è¯„åˆ†': score,
                'æŒç»­å¤©æ•°': int(curr['persist_days']),
                'é£é™©é¢„è­¦': risk_level,
                'å»ºè®®': "ç­‰å¾…3åˆ†" if score < 3 else "å¯åˆ†æ‰¹å»ºä»“",
                'å›æ’¤%': round(curr['retr'], 2),
                'RSI': round(curr['rsi'], 2),
                'BIAS': round(curr['bias'], 2),
                'price': round(curr['æ”¶ç›˜'], 4)
            }
    except: return None

def get_performance_stats():
    # æ­¤å‡½æ•°é€»è¾‘ä¿æŒå¤ç›˜ç»Ÿè®¡
    history_files = glob.glob('202*/**/*.csv', recursive=True)
    perf_list = []
    for h_file in history_files:
        if 'perf' in h_file: continue
        try:
            h_df = pd.read_csv(h_file)
            for _, sig in h_df.iterrows():
                code = str(sig['fund_code']).zfill(6)
                raw_path = f'fund_data/{code}.csv'
                if not os.path.exists(raw_path): continue
                
                raw_df = pd.read_csv(raw_path)
                if 'net_value' in raw_df.columns: raw_df = raw_df.rename(columns={'date': 'æ—¥æœŸ', 'net_value': 'æ”¶ç›˜'})
                raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                
                idx_list = raw_df[raw_df['æ—¥æœŸ'] == str(sig['date'])].index
                if not idx_list.empty:
                    curr_idx = idx_list[0]
                    recovery_df = raw_df.iloc[curr_idx+1:]
                    back_days = "æœªå›æœ¬"
                    back_idx = recovery_df[recovery_df['æ”¶ç›˜'] >= sig['price']].index
                    if not back_idx.empty: back_days = back_idx[0] - curr_idx
                    
                    future_10 = raw_df.iloc[curr_idx+1 : curr_idx+11]
                    if not future_10.empty:
                        max_up = (future_10['æ”¶ç›˜'].max() - sig['price']) / sig['price'] * 100
                        max_down = (future_10['æ”¶ç›˜'].min() - sig['price']) / sig['price'] * 100
                        status = "âœ…åå¼¹ä¸­" if max_up >= 1.0 else "âŒèµ°å¼±" if max_down <= -3.0 else "â³ç£¨åº•ä¸­"
                        
                        # è®¡ç®—å½“å‰æŒæœ‰æ”¶ç›Š (ä»ä¿¡å·ç‚¹åˆ°æœ€æ–°æ”¶ç›˜)
                        latest_price = raw_df.iloc[-1]['æ”¶ç›˜']
                        hold_return = (latest_price - sig['price']) / sig['price'] * 100

                        perf_list.append({
                            'æ—¥æœŸ': sig['date'], 'ä»£ç ': code,
                            'è¯„åˆ†': sig.get('è¯„åˆ†', 1), 'ç»“æœ': status,
                            'ç´¯ç§¯æ¶¨è·Œ%': round(hold_return, 2),
                            'å›æ’¤%': sig.get('å›æ’¤%', 0), 'RSI': sig.get('RSI', 0),
                            'å›æœ¬å¤©æ•°': back_days, 'å‘¨æœŸæœ€é«˜%': round(max_up, 2)
                        })
        except: continue
    return pd.DataFrame(perf_list)

def update_readme(current_res, perf_df):
    now_bj = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    content = f"# ğŸ¤– ETF/åŸºé‡‘ ç­–ç•¥é›·è¾¾ (å®æˆ˜åŠ å¼ºç‰ˆ)\n\n> æœ€åæ›´æ–°: `{now_bj}`\n\n"
    
    # 1. æ•ˆç‡ç»Ÿè®¡
    if not perf_df.empty:
        win_rate = (len(perf_df[perf_df['ç»“æœ'] == 'âœ…åå¼¹ä¸­']) / len(perf_df)) * 100
        content += f"## ğŸ“Š ç­–ç•¥æ•ˆç‡ (10æ—¥è¿½è¸ª)\n> **ç»¼åˆèƒœç‡**: `{win_rate:.2f}%` | **æ€»è®¡æ ·æœ¬**: `{len(perf_df)}` \n\n"

    # 2. å®æ—¶ç›‘æ§ (é«˜è¯„åˆ†æ’å‰é¢)
    content += "## ğŸ¯ å®æ—¶ä¿¡å·ç›‘æ§ (å«æŒç»­æ€§è¿½è¸ª)\n"
    if current_res:
        df = pd.DataFrame(current_res).sort_values(['è¯„åˆ†', 'å›æ’¤%'], ascending=[False, True])
        content += df.to_markdown(index=False) + "\n\n"
    else:
        content += "> ğŸ’¤ å½“å‰æ— ä¿¡å·ã€‚\n\n"

    # 3. ğŸ”¥ é‡ç‚¹å…³æ³¨ï¼šä¹°å…¥ä¿¡å·åçš„è¡¨ç°è¿½è¸ª
    content += "## ğŸ”¥ æ´»è·ƒä¹°ç‚¹è¿½è¸ª (è¯„åˆ†>=3 è¡¨ç°ç›‘æ§)\n"
    if not perf_df.empty:
        # åªè¿½è¸ªæœ€è¿‘14å¤©å†…å‡ºç°çš„3åˆ†ä»¥ä¸Šä¿¡å·
        recent_date = (datetime.now() - timedelta(days=14)).strftime('%Y-%m-%d')
        active_focus = perf_df[(perf_df['è¯„åˆ†'] >= 3) & (perf_df['æ—¥æœŸ'] >= recent_date)]
        if not active_focus.empty:
            content += active_focus[['æ—¥æœŸ', 'ä»£ç ', 'è¯„åˆ†', 'ç´¯ç§¯æ¶¨è·Œ%', 'ç»“æœ', 'å›æœ¬å¤©æ•°']].sort_values('æ—¥æœŸ', ascending=False).to_markdown(index=False) + "\n\n"
        else:
            content += "> â³ æœ€è¿‘ 14 å¤©æš‚æ— é«˜åˆ†ä¹°å…¥ä¿¡å·å‡ºç°ã€‚\n\n"

    # 4. å†å²å¤ç›˜
    content += "## ğŸ“ˆ å†å²æ•ˆæœå…¨æ™¯å¤ç›˜\n"
    if not perf_df.empty:
        content += perf_df.tail(15).iloc[::-1].to_markdown(index=False) + "\n"
    
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(content)

def main():
    files = glob.glob('fund_data/*.csv')
    with Pool(cpu_count()) as p:
        results = [r for r in p.map(process_file, files) if r is not None]
    
    if results:
        now = datetime.now()
        folder = now.strftime('%Y/%m')
        os.makedirs(folder, exist_ok=True)
        pd.DataFrame(results).to_csv(f"{folder}/sig_{now.strftime('%d_%H%M%S')}.csv", index=False)
    
    perf_df = get_performance_stats()
    update_readme(results, perf_df)

if __name__ == "__main__":
    main()
