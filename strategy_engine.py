import os
import glob
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
from multiprocessing import Pool, cpu_count

# ==========================================
# --- 1. æ ¸å¿ƒé”æ­»é£æ§ä¸ç­–ç•¥å‚æ•° ---
# ==========================================
TOTAL_BUDGET_CAP = 10000   # 1ä¸‡æœ¬é‡‘æ€»ä¸Šé™
PORTFOLIO_UNIT = 2000      # å•ç¬”æŠ„åº•é‡‘é¢
STOP_BUY_LOSS_RATIO = -5.0 # ç»„åˆæ€»äºæŸè¶…5%ï¼Œå¼€å¯ç¦ä¹°ä»¤
RETR_WATCH = -10.0         # å›æ’¤é˜ˆå€¼é”å®šä¸º -20.0
RETR_WINDOW = 250          # 250æ—¥å®æˆ˜å‘¨æœŸ
RSI_LOW = 30           
BIAS_LOW = -5.0        
LIQUIDITY_LIMIT = 10000000 # [é£æ§] æ—¥å‡æˆäº¤é¢ä½äº1000ä¸‡çš„ETFä¸ä»‹å…¥

# ==========================================
# --- 2. æ˜ å°„é€»è¾‘ï¼šåŠ è½½ ETF åç§° ---
# ==========================================
def load_name_mapping():
    mapping = {}
    try:
        if os.path.exists('ETFåˆ—è¡¨.txt'):
            try:
                df_map = pd.read_csv('ETFåˆ—è¡¨.txt', sep='\t', dtype={'è¯åˆ¸ä»£ç ': str})
            except:
                df_map = pd.read_csv('ETFåˆ—è¡¨.txt', sep='\t', dtype={'è¯åˆ¸ä»£ç ': str}, encoding='gbk')
            
            for _, row in df_map.iterrows():
                code = str(row['è¯åˆ¸ä»£ç ']).zfill(6)
                mapping[code] = row['è¯åˆ¸ç®€ç§°']
    except Exception as e:
        print(f"åç§°æ˜ å°„åŠ è½½å¤±è´¥: {e}")
    return mapping

NAME_MAP = load_name_mapping()

# ==========================================
# --- 3. æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ¨¡å— ---
# ==========================================
def calculate_rsi(series, period=6):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss.replace(0, np.nan)
    return 100 - (100 / (1 + rs.fillna(0)))

def check_rsi_divergence(df, window=20):
    """RSIåº•èƒŒç¦»æ£€æµ‹"""
    if len(df) < window + 5: return False
    curr_price = df['æ”¶ç›˜'].iloc[-1]
    curr_rsi = df['rsi'].iloc[-1]
    
    lookback_df = df.iloc[-(window+1):-1]
    if lookback_df.empty: return False
    
    min_price_idx = lookback_df['æ”¶ç›˜'].idxmin()
    min_price_val = lookback_df['æ”¶ç›˜'].min()
    min_price_rsi = lookback_df.loc[min_price_idx, 'rsi']
    
    if curr_price <= min_price_val and curr_rsi > min_price_rsi + 2:
        return True
    return False

# ==========================================
# --- 4. å•æ–‡ä»¶å¤„ç† (é€‚é…ä¸Šä¼ çš„CSVæ ¼å¼) ---
# ==========================================
def process_file(file_path):
    try:
        # æ”¯æŒå¤šç§ç¼–ç è¯»å–
        try: df = pd.read_csv(file_path, encoding='utf-8')
        except: df = pd.read_csv(file_path, encoding='gbk')
        
        # å­—æ®µå…¼å®¹æ€§æ¸…æ´—
        if 'æ—¥æœŸ' not in df.columns or 'æ”¶ç›˜' not in df.columns:
            return None
            
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)
        if len(df) < 30: return None

        # [æ–°å¢] æµåŠ¨æ€§è¿‡æ»¤ï¼šåŸºäºâ€œæˆäº¤é¢â€å­—æ®µ
        if 'æˆäº¤é¢' in df.columns:
            recent_avg_amount = df['æˆäº¤é¢'].iloc[-5:].mean()
            if recent_avg_amount < LIQUIDITY_LIMIT: return None

        # æ•°æ®å¼‚åŠ¨ç›‘æ§
        curr_p = df['æ”¶ç›˜'].iloc[-1]
        prev_p = df['æ”¶ç›˜'].iloc[-2]
        # æ‹¦æˆªç”±äºæ•°æ®æºé”™è¯¯å¯¼è‡´çš„å‡€å€¼å½’1 (å¦‚510010æ—©æœŸæ•°æ®ä¸º1.0å·¦å³ï¼Œéœ€ç»“åˆå‡å€¼åˆ¤æ–­)
        if curr_p == 1.0 and prev_p > 1.1: return None
        is_vol_alert = abs((curr_p - prev_p) / prev_p) > 0.09 

        # æŒ‡æ ‡è®¡ç®—
        df['rsi'] = calculate_rsi(df['æ”¶ç›˜'], 6)
        df['ma6'] = df['æ”¶ç›˜'].rolling(window=6).mean()
        df['bias'] = ((df['æ”¶ç›˜'] - df['ma6']) / df['ma6']) * 100
        df['max_high'] = df['æ”¶ç›˜'].rolling(window=RETR_WINDOW).max()
        df['retr'] = ((df['æ”¶ç›˜'] - df['max_high']) / df['max_high']) * 100
        
        df['in_watch'] = df['retr'] <= RETR_WATCH
        df['persist_days'] = df['in_watch'].groupby((df['in_watch'] != df['in_watch'].shift()).cumsum()).cumcount() + 1
        df.loc[~df['in_watch'], 'persist_days'] = 0

        curr = df.iloc[-1]
        code = os.path.splitext(os.path.basename(file_path))[0].zfill(6)
        name = NAME_MAP.get(code, "æœªçŸ¥å“ç§")
        
        if curr['in_watch']:
            score = 1
            divergence = check_rsi_divergence(df)
            if curr['rsi'] < RSI_LOW: score += 2
            if curr['bias'] < BIAS_LOW: score += 2
            if divergence: score += 2
            
            risk_level = "æ­£å¸¸"
            if is_vol_alert: risk_level = "âš ï¸å‡€å€¼å¼‚åŠ¨"
            elif divergence: risk_level = "ğŸ“ˆåº•èƒŒç¦»å½¢æˆ"
            elif curr['rsi'] > 55 and score == 1: risk_level = "ğŸš©é«˜é£é™©(é™·é˜±)"
            elif score >= 5: risk_level = "ğŸ”¥æé«˜èƒœç‡(èƒŒç¦»)"
            elif score >= 3: risk_level = "âœ…é«˜èƒœç‡åŒº"
                
            return {
                'date': str(curr['æ—¥æœŸ']).split(' ')[0],
                'fund_code': code,
                'åç§°': name,
                'è¯„åˆ†': score,
                'æŒç»­å¤©æ•°': int(curr['persist_days']),
                'é£é™©é¢„è­¦': risk_level,
                'å›æ’¤%': round(curr['retr'], 2),
                'RSI': round(curr['rsi'], 2),
                'BIAS': round(curr['bias'], 2),
                'price': round(curr['æ”¶ç›˜'], 4)
            }
    except: return None

# ==========================================
# --- 5. ç›ˆäºç»Ÿè®¡æ¨¡å— (åŒ…å«æœ€é«˜æµ®ç›ˆ) ---
# ==========================================
def get_performance_stats():
    history_files = glob.glob('202*/**/*.csv', recursive=True)
    perf_list = []
    for h_file in history_files:
        if 'perf' in h_file: continue
        try:
            h_df = pd.read_csv(h_file)
            for _, sig in h_df.iterrows():
                code = str(sig['fund_code']).zfill(6)
                raw_path = f'fund_data/{code}.csv'
                if not os.path.exists(raw_path): continue
                
                try: raw_df = pd.read_csv(raw_path, encoding='utf-8')
                except: raw_df = pd.read_csv(raw_path, encoding='gbk')
                
                raw_df['æ—¥æœŸ'] = pd.to_datetime(raw_df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                
                idx_list = raw_df[raw_df['æ—¥æœŸ'] == str(sig['date'])].index
                if not idx_list.empty:
                    curr_idx = idx_list[0]
                    signal_price = sig['price']
                    after_signal_df = raw_df.iloc[curr_idx:]
                    latest_price = after_signal_df['æ”¶ç›˜'].iloc[-1]
                    
                    if latest_price == 1.0 and signal_price > 1.1: continue
                    
                    max_price_after = after_signal_df['æ”¶ç›˜'].max()
                    max_profit = (max_price_after - signal_price) / signal_price * 100
                    
                    prev_price = raw_df.iloc[-2]['æ”¶ç›˜'] if len(raw_df) > 1 else latest_price
                    daily_raw = (latest_price - prev_price) / prev_price * 100
                    color_tag = "ğŸ”´ " if daily_raw > 0 else "ğŸŸ¢ " if daily_raw < 0 else ""
                    
                    total_hold_change = (latest_price - signal_price) / signal_price * 100
                    
                    recovery_df = raw_df.iloc[curr_idx+1:]
                    back_days = "æœªå›æœ¬"
                    back_idx = recovery_df[recovery_df['æ”¶ç›˜'] >= signal_price].index
                    if not back_idx.empty: back_days = int(back_idx[0] - curr_idx)
                    
                    perf_list.append({
                        'æ—¥æœŸ': sig['date'], 'ä»£ç ': code, 'åç§°': NAME_MAP.get(code, "æœªçŸ¥"),
                        'è¯„åˆ†': sig.get('è¯„åˆ†', 1), 'ä¿¡å·ä»·': round(signal_price, 4), 
                        'æœ€æ–°ä»·': round(latest_price, 4), 'ä»Šæ—¥æ¶¨è·Œ': f"{color_tag}{daily_raw:+.2f}%", 
                        'æœ€é«˜æµ®ç›ˆ%': round(max_profit, 2), 
                        'æ€»ç›ˆäº%': round(total_hold_change, 2), 'å›æœ¬å¤©æ•°': back_days,
                        'çŠ¶æ€': "âœ…åå¼¹ä¸­" if total_hold_change > 1 else "âŒèµ°å¼±" if total_hold_change < -3 else "â³ç£¨åº•ä¸­"
                    })
        except: continue
    return pd.DataFrame(perf_list)

# ==========================================
# --- 6. æŠ¥å‘Šç”Ÿæˆ (README) ---
# ==========================================
def update_readme(current_res, perf_df):
    now_bj = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')
    content = f"# ğŸ¤– ETF ç­–ç•¥é›·è¾¾ (250æ—¥å®æˆ˜ç‰ˆ)\n\n> æœ€åæ›´æ–°: `{now_bj}`\n\n"
    
    total_invested = 0
    total_profit_loss_val = 0
    avg_return_rate = 0
    is_budget_full = False
    is_panic_mode = False

    if not perf_df.empty:
        recent_limit = (datetime.now() - timedelta(days=14)).strftime('%Y-%m-%d')
        active_focus = perf_df[(perf_df['è¯„åˆ†'] >= 3) & (perf_df['æ—¥æœŸ'] >= recent_limit)].drop_duplicates(subset=['ä»£ç '])
        
        if not active_focus.empty:
            total_invested = len(active_focus) * PORTFOLIO_UNIT
            total_profit_loss_val = (active_focus['æ€»ç›ˆäº%'] / 100 * PORTFOLIO_UNIT).sum()
            avg_return_rate = (total_profit_loss_val / total_invested) * 100 if total_invested > 0 else 0
            is_budget_full = total_invested >= TOTAL_BUDGET_CAP
            is_panic_mode = avg_return_rate <= STOP_BUY_LOSS_RATIO

    content += "## ğŸ’° å®æˆ˜é£æ§æ§åˆ¶å°\n"
    content += f"> **æ¨¡æ‹Ÿä»“ä½**: `Â¥{total_invested} / Â¥{TOTAL_BUDGET_CAP}` | **è´¦æˆ·æ€»ç›ˆäº**: `Â¥{total_profit_loss_val:.2f} ({avg_return_rate:+.2f}%)`\n"
    status_str = "ğŸ›¡ï¸ çŠ¶æ€è‰¯å¥½"
    if is_budget_full: status_str = "â›” ä»“ä½å·²æ»¡"
    if is_panic_mode: status_str = "âŒ è§¦å‘ç¦ä¹°ä»¤(äºæŸè¿‡å¤§)"
    content += f"> **å½“å‰ç­–ç•¥**: `{status_str}`\n\n"

    content += "## ğŸ¯ æŠ„åº•ä¿¡å·æ±  (-20%å›æ’¤ + æŒ‡æ ‡åŠ åˆ†)\n"
    if current_res:
        df = pd.DataFrame(current_res).sort_values(['è¯„åˆ†', 'å›æ’¤%'], ascending=[False, True])
        def get_adv(r):
            if r['è¯„åˆ†'] < 3: return "â³ è§‚å¯Ÿä¸­"
            if is_budget_full or is_panic_mode: return "âŒ åœæ­¢å»ºä»“"
            return "âœ… åˆ†æ‰¹å»ºä»“"
        df['æ“ä½œå»ºè®®'] = df.apply(get_adv, axis=1)
        content += df.to_markdown(index=False) + "\n\n"
    else:
        content += "> ğŸ’¤ æš‚æ— è¶…è·Œå“ç§ã€‚\n\n"

    content += "## ğŸ”¥ ä¿¡å·åç»­è¿½è¸ª (æœ€é«˜æµ®ç›ˆå›ç›˜)\n"
    if not perf_df.empty:
        track_df = perf_df.sort_values('æ—¥æœŸ', ascending=False).head(15)
        content += track_df.to_markdown(index=False) + "\n\n"

    with open('README.md', 'w', encoding='utf-8') as f: f.write(content)

# ==========================================
# --- 7. ä¸»ç¨‹åº ---
# ==========================================
def main():
    files = glob.glob('fund_data/*.csv')
    with Pool(cpu_count()) as p:
        results = [r for r in p.map(process_file, files) if r is not None]
    
    if results:
        folder = datetime.now().strftime('%Y/%m')
        os.makedirs(folder, exist_ok=True)
        pd.DataFrame(results).to_csv(f"{folder}/sig_{datetime.now().strftime('%d_%H%M%S')}.csv", index=False)
    
    perf_df = get_performance_stats()
    update_readme(results, perf_df)

if __name__ == "__main__":
    main()
